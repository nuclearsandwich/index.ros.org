[{"id":64,"url":"/doc/ros2/Releases/Release-Ardent-Apalone/","title":"ROS 2 Ardent Apalone (codename ‘ardent’; December 2017)","content":"\nROS 2 Ardent Apalone (codename ‘ardent’; December 2017)¶\nWelcome to the first non-beta release of ROS 2 software named Ardent Apalone!\n\nSupported Platforms¶\nThis version of ROS 2 is supported on three platforms:\n\nUbuntu 16.04 (Xenial)\nMac OS X 10.12 (Sierra)\nWindows 10\n\nBinary packages as well as instructions for how to compile from source are provided for all 3 platforms (see install instructions as well as documentation).\n\n\nFeatures¶\n\nNew features in this ROS 2 release¶\n\nDistributed discovery, publish / subscribe, request / response communication\n\nProvided by a C API\nImplemented using different vendors:\n\neProsima’s FastRTPS as well as ADLINK’s OpenSplice (from binary and source)\nRTI’s Connext (only from source)\n\n\nNumerous quality of service settings for handling non-ideal networks\nDDS Security support (with Connext and FastRTPS)\n\n\nC++ and Python 3 client libraries\n\nSharing common code in C to unify the implementation\nExecution model separated from the nodes, composable nodes\nNode-specific parameters (only in C++ atm)\nLife cycle (only in C++ atm)\nOptionally intra-process communication using the same API (only in C++)\n\n\nMessage definitions (with bounded arrays and strings as well as default values)\nCommand line tools (e.g. ros2 run)\nrviz with a few display types (the Windows version will likely follow in a few weeks)\nFile system-based resource index (querying information without recursive crawling)\nRealtime safe code paths for pub / sub (with compatible DDS implementations only)\nBridge between ROS 1 and ROS 2\nHSR demo see Beta 3\nTurtlebot demo see Beta 2\n\nFor a more detailed description please see the Features page.\n\n\nChanges since Beta 3 release¶\nImprovements since the Beta 3 release:\n\nrviz\nDifferent initialization options for message data structures in C++ (see design doc)\nLogging API improvements, now also used in the demos\nTime support in C++ with different clocks\nwait-for-service support in the Python client library\nDraft implementation of REP 149 specifying format 3 of the package manifest files\n\n\n\n\nKnown Issues¶\n\nFastRTPS performance with larger data like the image demo\nUsing Connext it is currently not allowed for two topics with the same base name but different namespaces to have a different type (see issue).\nListing of node names (e.g. using ros2 node list) does not work across some rmw implementations.\nOn Windows Python launch files might hang when trying to abort using Ctrl-C (see issue). In order to continue using the shell which is blocked by the hanging command you might want to end the hanging Python process using the process monitor.\n\n\n\n"},{"id":65,"url":"/doc/ros2/Releases/Release-Bouncy-Bolson/","title":"ROS 2 Bouncy Bolson (codename ‘bouncy’; June 2018)","content":"\nROS 2 Bouncy Bolson (codename ‘bouncy’; June 2018)¶\n\nTable of Contents\n\nSupported Platforms\nFeatures\n\nNew features in this ROS 2 release\nChanges since the Ardent release\n\n\nKnown Issues\n\n\nBouncy Bolson is the second release of ROS 2.\n\nSupported Platforms¶\nThis version of ROS 2 is supported on four platforms (see REP 2000 for full details):\n\nUbuntu 18.04 (Bionic)\n\nDebian packages for amd64 as well as arm64\n\n\nUbuntu 16.04 (Xenial)\n\nno Debian packages but building from source is supported\n\n\nMac OS X 10.12 (Sierra)\nWindows 10 with Visual Studio 2017\n\nBinary packages as well as instructions for how to compile from source are provided (see install instructions as well as documentation).\n\n\nFeatures¶\n\nNew features in this ROS 2 release¶\n\nNew launch system featuring a much more capable and flexible Python API.\nParameters can be passed as command line arguments to C++ executables.\nStatic remapping via command line arguments.\nVarious improvements to the Python client library.\nSupport for publishing and subscribing to serialized data.\nThis is the foundation for the upcoming work towards a native rosbag implementation.\nMore command line tools, e.g. for working with parameters and lifecycle states.\nBinary packages / fat archives support three RMW implementations by default (without the need to build from source):\n\neProsima’s FastRTPS (default)\nRTI’s Connext\nADLINK’s OpenSplice\n\n\n\nFor an overview of all features available, including those from earlier releases, please see the Features page.\n\n\nChanges since the Ardent release¶\nChanges since the Ardent Apalone release:\n\nThe Python package launch has been redesigned.\nThe previous Python API has been moved into a submodule launch.legacy.\nYou can update existing launch files to continue to use the legacy API if a transition to the new Python API is not desired.\nThe ROS topic names containing namespaces are mapped to DDS topics including their namespaces.\nDDS partitions are not being used anymore for this.\nThe recommended build tool is now colcon instead of ament_tools.\nThis switch has no implications for the code in each ROS 2 package.\nThe install instructions have been updated and the read-the-docs page describes how to map an existing ament_tools call to colcon.\nThe argument order of this rclcpp::Node::create_subscription() signature has been modified.\n\n\n\n\nKnown Issues¶\n\nNew-style launch files may hang on shutdown for some combinations of platform and RMW implementation.\nStatic remapping of namespaces not working correctly when addressed to a particular node.\nOpensplice error messages may be printed when using ros2 param and ros2 lifecycle command-line tools.\n\n\n\n"},{"id":66,"url":"/doc/ros2/Releases/Release-Crystal-Clemmys/","title":"ROS 2 Crystal Clemmys (codename ‘crystal’; December 2018)","content":"\nROS 2 Crystal Clemmys (codename ‘crystal’; December 2018)¶\n\nTable of Contents\n\nSupported Platforms\nNew features in this ROS 2 release\nChanges since the Bouncy release\nKnown Issues\n\n\nCrystal Clemmys is the third release of ROS 2.\n\nSupported Platforms¶\nCrystal Clemmys is primarily supported on the following platforms (see REP 2000 for full details):\nTier 1 platforms:\n\nUbuntu 18.04 (Bionic)\nMac OS X 10.12 (Sierra)\nWindows 10\n\nTier 2 platforms:\n\nUbuntu 16.04 (Xenial)\n\n\n\nNew features in this ROS 2 release¶\n\nActions in C / C++ (server / client examples)\ngazebo_ros_pkgs\nimage_transport\nnavigation2\nrosbag2\nrqt\nImprovement in memory management\nIntrospection information about nodes\nLaunch system improvements\n\nArguments\nNested launch files\nConditions\nPass params to Nodes\n\n\nLaid the groundwork for file-based logging and /rosout publishing\nTime and Duration API in Python\nParameters work with Python nodes\n\n\n\nChanges since the Bouncy release¶\nChanges since the Bouncy Bolson release:\n\ngeometry2 - tf2_ros::Buffer API Change\ntf2_ros::Buffer now uses rclcpp::Time, with the constructor requiring a shared_ptr to a rclcpp::Clock instance.\nSee https://github.com/ros2/geometry2/pull/67 for details, with example usage:\n#include <tf2_ros/transform_listener.h>\n#include <rclcpp/rclcpp.hpp>\n...\n# Assuming you have a rclcpp::Node my_node\ntf2_ros::Buffer buffer(my_node.get_clock());\ntf2_ros::TransformListener tf_listener(buffer);\n\n\n\nAll rclcpp and rcutils logging macros require semicolons.\nSee https://github.com/ros2/rcutils/issues/113 for details.\n\nrcutils_get_error_string_safe() and rcl_get_error_string_safe() have been replaced with rcutils_get_error_string().str and rcl_get_error_string().str.\nSee https://github.com/ros2/rcutils/pull/121 for details.\n\nrmw - rmw_init API Change\nThere are two new structs, the rcl_context_t and the rcl_init_options_t, which are used with rmw_init.\nThe init options struct is used to pass options down to the middleware and is an input to rmw_init.\nThe context is a handle which is an output of rmw_init function is used to identify which init-shutdown cycle each entity is associated with, where an “entity” is anything created like a node, guard condition, etc.\nThis is listed here because maintainers of alternative rmw implementations will need to implement these new functions to have their rmw implementation work in Crystal.\nThis is the function that had a signature change:\n\nrmw_init\n\nAdditionally, there are these new functions which need to be implemented by each rmw implementation:\n\nrmw_shutdown\nrmw_init_options_init\nrmw_init_options_copy\nrmw_init_options_fini\n\nHere’s an example of what minimally needs to be changed in an rmw implementation to adhere to this API change:\n\nrmw_fastrtps pr\n\n\nrcl - rcl_init API Change\nLike the rmw change above, there’s two new structs in rcl called rcl_context_t and rcl_init_options_t.\nThe init options are passed into rcl_init as an input and the context is passed in as an output.\nThe context is used to associate all other rcl entities to a specific init-shutdown cycle, effectively making init and shutdown no longer global functions, or rather those functions no longer use an global state and instead encapsulate all state within the context type.\nAny maintainers of a client library implementation (that also uses rcl under the hood) will need to make changes to work with Crystal.\nThese functions were removed:\n\nrcl_get_global_arguments\nrcl_get_instance_id\nrcl_ok\n\nThese functions had signature changes:\n\nrcl_init\nrcl_shutdown\nrcl_guard_condition_init\nrcl_guard_condition_init_from_rmw\nrcl_node_init\nrcl_timer_init\n\nThese are the new functions and types:\n\nrcl_context_t\nrcl_get_zero_initialized_context\nrcl_context_fini\nrcl_context_get_init_options\nrcl_context_get_instance_id\nrcl_context_is_valid\nrcl_init_options_t\nrcl_get_zero_initialized_init_options\nrcl_init_options_init\nrcl_init_options_copy\nrcl_init_options_fini\nrcl_init_options_get_rmw_init_options\nrcl_node_is_valid_except_context\nrcl_publisher_get_context\nrcl_publisher_is_valid_except_context\n\nThese new and changed functions will impact how you handle init and shutdown in your client library.\nFor examples, look at the following rclcpp and rclpy PR’s:\n\nrclcpp\nrclpy\n\nHowever, you may just continue to offer a single, global init and shutdown in your client library, and just store a single global context object.\n\n\n\n\nKnown Issues¶\n\nCross-vendor communication between rmw_fastrtps_cpp and other implementations is not functioning on Windows (Issue).\n100% CPU usage in Action Server when cancelling a goal from the client. (Issue).\nAction Server can crash when a goal expires. (Pull Request).\nSegfault in ros2 param get when a string parameter value contains non-ASCII characters. (Issue).\nThe latest version of OpenSplice on Windows is not compatible with the available binaries. (Issue).\n\n\n\n"},{"id":67,"url":"/doc/ros2/Contributing/Developer-Guide/","title":"ROS 2 Developer Guide","content":"\nROS 2 Developer Guide¶\n\nTable of Contents\n\nGeneral Principles\nGeneral Practices\n\nIssues\nPull requests\nDevelopment Process\nChanges to RMW API\nkanban board (waffle.io)\nProgramming conventions\n\n\nLanguage Versions and Code Format\n\nC\nC++\nPython\nCMake\nMarkdown\nJavascript\n\n\nTesting\n\nTest Coverage\n\n\nVersioning\nFilesystem Layout\n\nPackage layout\nRepository layout\n\n\nDocumentation\nPackage Categories\n\n(Level 1)\n(Level 2)\n(Level 3)\n(Level 4)\n\n\n\n\nThis page defines the practices and policies we employ when developing ROS 2.\n\nGeneral Principles¶\nSome principles are common to all ROS 2 development:\n\nShared ownership: Everybody working on ROS2 should feel ownership over all parts of the system.\nThe original author of a chunk of code does not have any special permission or obligation to control or maintain that chunk of code.\nEveryone is free to propose changes anywhere, to handle any type of ticket, and to review any pull request.\nBe willing to work on anything: As a corollary to shared ownership, everybody should be willing to take on any available task and contribute to any aspect of the system.\nAsk for help: If you run into trouble on something, ask your fellow developers for help, via tickets, comments, or email, as appropriate.\n\n\n\nGeneral Practices¶\nSome practices are common to all ROS 2 development:\n\nIssues¶\nWhen filing an issue please make sure to:\n\nInclude enough information for another person to understand the issue.\nIn ROS 2, the following points are needed for narrowing down the cause of an issue. Testing with as many alternatives in each category as feasible will be especially helpful.\n- The operating system and version. Reasoning: ROS 2 supports multiple platforms, and some bugs are specific to particular versions of operating systems/compilers.\n- The installation method. Reasoning: Some issues only manifest if ROS 2 has been installed from “fat archives” or from Debians. This can help us determine if the issue is with the packaging process.\n- The specific version of ROS 2. Reasoning: Some bugs may be present in a particular ROS 2 release and later fixed. It is important to know if your installation includes these fixes.\n- The DDS/RMW implementation being used (see this page for how to determine which one). Reasoning: Communication issues may be specific to the underlying ROS middleware being used.\n- The ROS 2 client library being used. Reasoning: This helps us narrow down the layer in the stack at which the issue might be.\nInclude a list of steps to reproduce the issue.\nIn case of a bug consider to provide a short, self contained, correct (compilable), example. Issues are much more likely to be resolved if others can reproduce them easily.\nMention troubleshooting steps that have been tried already, including:\n- Upgrading to the latest version of the code, which may include bug fixes that have not been released yet. See this section and follow the instructions to get the “master” branches.\n- Trying with a different RMW implementation. See this page for how to do that.\n\n\n\nPull requests¶\n\nA pull request should only focus on one change.\nSeparate changes should go into separate pull requests.\nSee GitHub’s guide to writing the perfect pull request.\nA patch should be minimal in size and avoid any kind of unnecessary changes.\nAlways run CI jobs for all platforms for every pull request and include links to jobs in the pull request.\n(If you don’t have access to the Jenkins job someone will trigger the jobs for you.)\nBefore merging a pull request all changes should be squashed into a small number of semantic commits to keep the history clear.\n\nBut avoid squashing commits while a pull request is under review.\nYour reviewers might not notice that you made the change, thereby introducing potential for confusion.\nPlus, you’re going to squash before merging anyway; there’s no benefit to doing it early.\n\n\nA minimum of 1 +1 from a fellow developer is required to consider a pull request to be approved, which is required before merging.\nAny developer is welcome to review and approve a pull request (see General Principles).\nWhen you start reviewing a pull request, comment on the pull request so that other developers know that you’re reviewing it.\nPull-request review is not read-only, with the reviewer making comments and then waiting for the author to address them.\nAs a reviewer, feel free to make minor improvements (typos, style issues, etc.) in-place.\nAs the opener of a pull-request, if you are working in a fork, checking the box to allow edits from upstream contributors will assist with the aforementioned.\nAs a reviewer, also feel free to make more substantial improvements, but consider putting them in a separate branch (either mention the new branch in a comment, or open another pull request from the new branch to the original branch).\nAny developer (the author, the reviewer, or somebody else) can merge any approved pull request.\n\n\n\nDevelopment Process¶\n\nThe default branch (in most cases the master branch) must always build, pass all tests and compile without warnings.\nIf at any time there is a regression it is the top priority to restore at least the previous state.\nAlways build with tests enabled.\nAlways run tests locally after changes and before proposing them in a pull request.\nBesides using automated tests, also run the modified code path manually to ensure that the patch works as intended.\nAlways run CI jobs for all platforms for every pull request and include links to the jobs in the pull request.\n\n\n\nChanges to RMW API¶\nWhen updating RMW API, it is required that RMW implementations for the Tier 1 middleware libraries are updated as well.\nFor example, a new function rmw_foo() introduced to the RMW API must be implemented in the following packages (as of ROS Crystal):\n\nrmw_fastrtps\nrmw_connext\n\nUpdates for non-Tier 1 middleware libraries should also be considered if feasible (e.g. depending on the size of the change).\nSee REP-2000 for the list of middleware libraries and their tiers.\n\n\nkanban board (waffle.io)¶\nTo help organize the work, the core ROS 2 development team is using a kanban system hosted at waffle.io: ROS 2 kanban.\nThis board augments the capabilities of GitHub by using labels to give a custom view into issues and pull requests across multiple repositories.\nThe data produced and edited via waffle.io are stored in the underlying GitHub objects, so there’s no requirement to use waffle.io (or for the core team to be tied to it); it just provides a useful perspective on things.\nHere’s how we’re using the columns in the board:\n\nBacklog: cards (issues) that nobody is yet working on.\nTheir order in the backlog is an approximate indicator of priority, with cards higher in the column having higher priority.\nReady: cards on which work will be started very soon.\nCards in this column should have an owner assigned.\nCards should not sit in this column for more than a few days.\nIn Progress: cards on which work is currently in progress.\nCards in this column must have an owner assigned.\nCards should not sit in this column for more than a week.\nWhen it is determined that a card will take longer, break it up into multiple cards and put the extras in the backlog.\nIn Review: cards for which the work is done and the relevant pull request/s is/are ready for review.\nCards remain in this column during review, but if review uncovers significant extra work to be done, move the card into an earlier column as appropriate.\nDone: cards for which the work is done, meaning that the relevant pull request/s has/have been merged.\nThis column shows recently completed cards, for informational purposes only.\n\nTips for working with the kanban board:\n\nRequesting permission to make changes. Simply comment on specific tickets that you want to work on it. Depending on the complexity it might be useful to describe how you want to address it. We will update the status (if you don’t have the permission) and you can start working on a pull request. If you contribute regularly we will likely just grant you permission to manage the labels etc. yourself.\nUsing markup to connect issues and pull requests (see the waffle.io FAQ).\nDoing equivalent things outside waffle.io, directly via GitHub. The column a card is in is determined by the label. The first and last column do not require a specific label. For the other column a label with the same name can be assigned.\n\n\n\nProgramming conventions¶\n\nDefensive programming: ensure that assumptions are held as early as possible.\nE.g. check every return code and make sure to at least throw an exception until the case is handled more gracefully.\nAll error messages must be directed to stderr.\nDeclare variables in the narrowest scope possible.\nKeep group of items (dependencies, imports, includes, etc.) ordered alphabetically.\n\n\nC++ specific¶\n\nAvoid using direct streaming (<<) to stdout / stderr to prevent interleaving between multiple threads.\nAvoid using references for std::shared_ptr since that subverts the reference counting. If the original instance goes out of scope and the reference is being used it accesses freed memory.\n\n\n\n\n\nLanguage Versions and Code Format¶\nIn order to achieve a consistent looking product we will all follow externally (if possible) defined style guidelines for each language.\nFor other things like package layout or documentation layout we will need to come up with our own guidelines, drawing on current, popular styles in use now.\nAdditionally, where ever possible, developers should use integrated tools to allow them to check that these guidelines are followed in their editors.\nFor example, everyone should have a PEP8 checker built into their editor to cut down on review iterations related to style.\nAlso where possible, packages should check style as part of their unit tests to help with the automated detection of style issues (see ament_lint_auto).\n\nC¶\n\nStandard¶\nWe will target C99.\n\n\nStyle¶\nWe will use Python’s PEP7 for our C style guide, with some modifications and additions:\n\nWe will target C99, as we do not need to support C89 (as PEP7 recommends)\n\nrationale: among other things it allows us to use both // and /* */ style comments\nrationale: C99 is pretty much ubiquitous now\n\n\nC++ style // comments are allowed\nAlways place literals on the left hand side of comparison operators, e.g. 0 == ret instead of ret == 0\n\nrationale: ret == 0 too easily turns into ret = 0 by accident\n\n\n\nAll of the following modifications only apply if we are not writing Python modules:\n\nDo not use Py_ as a prefix for everything\n\ninstead use a CamelCase version of the package name or other appropriate prefix\n\n\nThe stuff about documentation strings doesn’t apply\n\nWe can use the pep7 python module for style checking. The editor integration seems slim, we may need to look into automated checking for C in more detail.\n\n\n\nC++¶\n\nStandard¶\nWe will target C++14, using new built-in C++14 features over Boost equivalents where ever possible.\n\n\nStyle¶\nWe will use the Google C++ Style Guide, with some modifications:\n\nLine Length¶\n\nOur maximum line length is 100 characters.\n\n\n\nVariable Naming¶\n\nFor global variables use lowercase with underscores prefixed with g_\n\nrationale: keep variable naming case consistent across the project\nrationale: easy to tell the scope of a variable at a glance\nconsistency across languages\n\n\n\n\n\nFunction and Method Naming¶\n\nGoogle style guide says CamelCase, but the C++ std library’s style of snake_case is also allowed\n\nrationale: ROS 2 core packages currently use snake_case\n\nreason: either an historical oversight or a personal preference that didn’t get checked by the linter\nreason for not changing: retroactively changing would be too disruptive\n\n\nother considerations:\n\ncpplint.py does not check this case (hard to enforce other than with review)\nsnake_case can result in more consistency across languages\n\n\nspecific guidance:\n\nfor existing projects, prefer the existing style\nfor new projects, either is acceptable, but a preference for matching related existing projects is advised\nfinal decision is always developer discretion\n\nspecial cases like function pointers, callable types, etc. may require bending the rules\n\n\nNote that classes should still use CamelCase by default\n\n\n\n\n\n\n\nAccess Control¶\n\nDrop requirement for all class members to be private and therefore require accessors\n\nrationale: this is overly constraining for user API design\nwe should prefer private members, only making them public when they are needed\nwe should consider using accessors before choosing to allow direct member access\nwe should have a good reason for allowing direct member access, other than because it is convenient for us\n\n\n\n\n\nExceptions¶\n\nExceptions are allowed\n\nrationale: this is a new code base, so the legacy argument doesn’t apply to us\nrationale: for user facing API’s it is more idiomatic C++ to have exceptions\nExceptions in destructors should be explicitly avoided\n\n\nWe should consider avoiding Exceptions if we intend to wrap the resulting API in C\n\nrationale: it will make it easier to wrap in C\nrationale: most of our dependencies in code we intend to wrap in C do not use exceptions anyways\n\n\n\n\n\nFunction-like Objects¶\n\nNo restrictions on Lambda’s or std::function or std::bind\n\n\n\nBoost¶\n\nBoost should be avoided until absolutely required\n\n\n\nComments and Doc Comments¶\n\nUse /// and /** */ comments for documentation purposes and // style comments for notes and general comments\n\nClass and Function comments should use /// and /** */ style comments\nrationale: these are recommended for Doxygen and Sphinx in C/C++\nrationale: mixing /* */ and // is convenient for block commenting out code which contains comments\nDescriptions of how the code works or notes within classes and functions should use // style comments\n\n\n\n\n\nPointer Syntax Alignment¶\n\nUse char * c; instead of char* c; or char *c; because of this scenario char* c, *d, *e;\n\n\n\nClass Privacy Keywords¶\n\nDo not put 1 space before public:, private:, or protected:, it is more consistent for all indentions to be a multiple of 2\n\nrationale: most editors don’t like indentions which are not a multiple of the (soft) tab size\nUse zero spaces before public:, private:, or protected:, or 2 spaces\nIf you use 2 spaces before, indent other class statements by 2 additional spaces\nPrefer zero spaces, i.e. public:, private:, or protected: in the same column as the class\n\n\n\n\n\nNested Templates¶\n\nNever add whitespace to nested templates\n\nPrefer set<list<string>> (C++11 feature) to set<list<string> > or set< list<string> >\n\n\n\n\n\nAlways Use Braces¶\n\nAlways use braces following if, else, do, while, and for, even when the body is a single line.\n\nrationale: less opportunity for visual ambiguity and for complications due to use of macros in the body\n\n\n\n\n\nOpen Versus Cuddled Braces¶\n\nUse open braces for function, class, and struct definitions, but cuddle braces on if, else, while, for, etc…\n\nException: when an if (or while, etc.) condition is long enough to require line-wrapping, then use an open brace (i.e., don’t cuddle).\n\n\nWhen a function call cannot fit on one line, wrap at the open parenthesis (not in between arguments) and start them on the next line with a 2-space indent.  Continue with the 2-space indent on subsequent lines for more arguments.  (Note that the Google style guide is internally contradictory on this point.)\n\nSame goes for if (and while, etc.) conditions that are too long to fit on one line.\n\n\n\n\n\nExamples¶\nThis is OK:\nint main(int argc, char **argv)\n{\n  if (condition) {\n    return 0;\n  } else {\n    return 1;\n  }\n}\n\nif (this && that || both) {\n  ...\n}\n\n// Long condition; open brace\nif (\n  this && that || both && this && that || both && this && that || both && this && that)\n{\n  ...\n}\n\n// Short function call\ncall_func(foo, bar);\n\n// Long function call; wrap at the open parenthesis\ncall_func(\n  foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar,\n  foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar);\n\n// Very long function argument; separate it for readability\ncall_func(\n  bang,\n  fooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo,\n  bar, bat);\n\n\nThis is not OK:\nint main(int argc, char **argv) {\n  return 0;\n}\n\nif (this &&\n    that ||\n    both) {\n  ...\n}\n\n\nUse open braces rather than excessive indention, e.g. for distinguishing constructor code from constructor initializer lists\nThis is OK:\nReturnType LongClassName::ReallyReallyReallyLongFunctionName(\n  Type par_name1,  // 2 space indent\n  Type par_name2,\n  Type par_name3)\n{\n  DoSomething();  // 2 space indent\n  ...\n}\n\nMyClass::MyClass(int var)\n: some_var_(var),\n  some_other_var_(var + 1)\n{\n  ...\n  DoSomething();\n  ...\n}\n\n\nThis is not OK, even weird (the google way?):\nReturnType LongClassName::ReallyReallyReallyLongFunctionName(\n    Type par_name1,  // 4 space indent\n    Type par_name2,\n    Type par_name3) {\n  DoSomething();  // 2 space indent\n  ...\n}\n\nMyClass::MyClass(int var)\n    : some_var_(var),             // 4 space indent\n      some_other_var_(var + 1) {  // lined up\n  ...\n  DoSomething();\n  ...\n}\n\n\n\n\nLinters¶\nMost of these styles and restrictions can be checked with a combination of Google’s cpplint.py and uncrustify, though we may need to modify them slightly for our above changes.\nWe provide command line tools with custom configurations:\n\nament_cpplint\nament_uncrustify: configuration\n\nWe also run other tools to detect and eliminate as many warnings as possible.\nHere’s a non-exhaustive list of additional things we try to do on all of our packages:\n\nuse compiler flags like -Wall -Wextra -Wpedantic\nrun static code analysis like cppcheck, which we have integrated in ament_cppcheck.\n\n\n\n\n\nPython¶\n\nVersion¶\nWe will target Python 3 for our development.\n\n\nStyle¶\nWe will use the PEP8 guidelines for code format.\nWe chose the following more precise rule where PEP 8 leaves some freedom:\n\nWe allow up to 100 character per line (fifth paragraph).\nWe pick single quotes over double quotes as long as no escaping is necessary.\n\nTools like the (ament_)pep8 Python package should be used in unit-test and/or editor integration for checking Python code style.\nThe pep8 configuration used in the linter is here.\nIntegration with editors:\n\natom: https://atom.io/packages/linter-pep8\nemacs: http://kwbeam.com/emacs-for-python-i.html\nSublime Text: https://sublime.wbond.net/packages/SublimeLinter-flake8\nvim: https://github.com/nvie/vim-flake8\n\n\n\n\nCMake¶\n\nVersion¶\nWe will target CMake 3.5.\n\n\nStyle¶\nSince there is not an existing CMake style guide we will define our own:\n\nUse lowercase keywords (functions and macros).\nUse empty else() and end...() commands.\nNo whitespace before (‘s.\nUse two spaces of indention, do not use tabs.\nDo not use aligned indentation for parameters of multi-line macro invocations. Use two spaces only.\nPrefer functions with set(PARENT_SCOPE) to macros.\nWhen using macros prefix local variables with _ or a reasonable prefix.\n\n\n\n\nMarkdown¶\n\nStyle¶\nThe following rules to format the markdown syntax is intended to increase readability as well as versioning.\n\nEach section title should be preceded by one empty line and succeeded by one empty line.\n\nRationale: It expedites to get an overview about the structure when screening the document.\n\n\nEach sentence must start on a new line.\n\nRationale: For longer paragraphs a single change in the beginning makes the diff unreadable since it carries forward through the whole paragraph.\n\n\nEach sentence can optionally be wrapped to keep each line short.\nThe lines should not have any trailing white spaces.\nA code block must be preceded and succeeded by an empty line.\n\nRationale: Whitespace is significant only directly before and directly after fenced code blocks.\nFollowing these instructions will ensure that highlighting works properly and consistently.\n\n\nA code block should specify a syntax after the opening triple backticks.\n\n\n\n\nJavascript¶\n(Speculative, not yet used)\n\nVersion¶\nWe will target Javascript 1.5, which seems to provide the best balance of support in browsers and languages (node.js) and new features.\n\n\nStyle¶\nWe will use the airbnb Javascript Style guide.\nThe repository referred to above comes with a jshintrc file which allows the style to be enforced using jshint.\nEditor integration for jshint include vim, emacs, Sublime Text, and others can be found here.\n\n\n\n\nTesting¶\nAll packages should have some level of tests.\nTests can be broken down into three main categories: System tests, Integration tests, and Unit tests.\nUnit tests should always be in the package which is being tested and should make use of tools like Mock to try and test narrow parts of the code base in constructed scenarios.\nUnit tests should not bring in test dependencies that are not testing tools, e.g. gtest, nosetest, pytest, mock, etc…\nIntegration tests can test interactions between parts of the code or between parts of the code and the system.\nThey often test software interfaces in ways that we expect the user to use them.\nLike Unit tests, Integration tests should be in the package which is being tested and should not bring in non-tool test dependencies unless absolutely necessary, i.e. all non-tool dependencies should only be allowed under extreme scrutiny so they should be avoided if possible.\nSystem tests are designed to test end-to-end situations between packages and should be in their own packages to avoid bloating or coupling packages and to avoid circular dependencies.\nIn general minimizing external or cross package test dependencies should be avoided to prevent circular dependencies and tightly coupled test packages.\nAll packages should have some unit tests and possibly integration tests, but the degree to which they should have them is based on the package’s category (described later).\n\nTest Coverage¶\nSome packages should have a mechanism setup to capture test coverage information (if applicable to the language).\nCoverage tools exist for some of the languages described here including C, C++, and Python, but possibly others.\nWhen possible coverage should be measured in terms of branch coverage, as opposed to statement or function coverage.\n\n\n\nVersioning¶\n(Planned; not yet used)\nWe will use the Semantic Versioning guidelines for versioning.\nAnything below version 1.0.0 is free to make changes at will and for most of our near-term development this will be the case.\nIn general though for versions less than 1.0.0 we should increment the minor (as major.minor.patch) when we break existing API and increment patch for anything else.\nAnother part of adhering to the Semantic Versioning guidelines is that every package must declare a public API.\nThe declaration for most C and C++ packages is simple, it is any header that it installs, but it is acceptable to define a set of symbols which are considered private.\nWhen ever possible having private symbols in public headers should be avoided.\nFor other languages like Python, a public API must be explicitly defined, so that it is clear what symbols can be relied on with respect to the versioning guidelines.\nThe public API can also be extended to build artifacts like configuration variables, CMake config files, etc. as well as executables and command line options and output.\nAny elements of the public API should be clearly stated in the package’s documentation.\nIf something you are using is not explicitly listed as part of the public API in the package’s documentation, then you cannot depend on it not changing between minor or patch versions.\nWith respect to library versioning, we will version all libraries within a package together.\nThis means that libraries inherit their version from the package.\nThis keeps library and package versions from diverging and shares reasoning with the policy of releasing packages which share a repository together.\nIf you need libraries to have different versions then consider splitting them into different packages.\n\n\nFilesystem Layout¶\nThe filesystem layout of packages and repositories should follow the same conventions in order to provide a consistent experience for users browsing our source code.\n\nPackage layout¶\n\nsrc: contains all C and C++ code\n\nAlso contains C/C++ headers which are not installed\n\n\ninclude: contains all C and C++ headers which are installed\n\n<package name>: for all C and C++ installed headers they should be folder namespaced by the package name\n\n\n<package_name>: contains all Python code\ntest: contains all automated tests and test data\ndoc: contains all the documentation\npackage.xml: as defined by REP-0140 (may be updated for prototyping)\nCMakeLists.txt: only ROS packages which use CMake\nsetup.py: only ROS packages which use Python code only\nREADME: README which can be rendered on Github as a landing page for the project\n\nThis can be as short or detailed as is convenient, but it should at least link to project documentation\nConsider putting a CI or code coverage tag in this readme\nIt can also be .rst or anything else that Github supports\n\n\nLICENSE: A copy of the license or licenses for this package\nCHANGELOG.rst: REP-0132 compliant changelog\n\n\n\nRepository layout¶\nEach package should be in a subfolder which has the same name as the package.\nIf a repository contains only a single package it can optionally be in the root of the repository.\nThe root of the repository should have a CONTRIBUTING file describing the contribution guidelines.\nThis might include license implication when using e.g. the Apache 2 License.\n\n\n\nDocumentation¶\n(API docs are not yet being automatically generated)\nAll packages should have these documentation elements:\n\nDescription and purpose\nDefinition and description of the public API\nExamples\nHow to build and install (should reference external tools/workflows)\nHow to build and run tests\nHow to build documentation\nHow to develop (useful for describing things like python setup.py develop)\n\nEach package should describe itself and its purpose or how it is used in the larger scope.\nThe description should be written, as much as possible, assuming that the reader has stumbled onto it without previous knowledge of ROS or other related projects.\nEach package should define and describe its public API so that there is a reasonable expectation for users what is covered by the semantic versioning policy.\nEven in C and C++, where the public API can be enforced by API and ABI checking, it is a good opportunity to describe the layout of the code and the function of each part of the code.\nIt should be easy to take any package and from that package’s documentation understand how to build, run, build and run tests, and build the documentation.\nObviously we should avoid repeating ourselves for common workflows, like build a package in a workspace, but the basic workflows should be either described or referenced.\nFinally, it should include any documentation for developers.\nThis might include workflows for testing the code using something like python setup.py develop, or it might mean describing how to make use of extension points provided by you package.\nExamples:\n\ncapabilities: http://docs.ros.org/hydro/api/capabilities/html/\n\nThis one gives an example of docs which describe the public API\n\n\ncatkin_tools: https://catkin-tools.readthedocs.org/en/latest/development/extending_the_catkin_command.html\n\nThis is an example of describing an extension point for a package\n\n\n\n\n\nPackage Categories¶\n(Planned; not yet used)\nThe policies will apply differently to packages depending on their categorization.\nThe categories are meant to give some expectation as to the quality of a package and allows us to be more strict or compliant with some packages and less so with others.\n\n(Level 1)¶\nThis category should be used for packages which are required for a reasonable ROS system in a production environment.\nThat is to say that after you remove development tools, build tools, and introspection tools, these packages are still left over as requirements for a basic ROS system to run.\nHowever, just because you can conceive a system which does not need a particular package does not mean that it shouldn’t be called ‘Level 1’, in fact the opposite is true.\nIf we can imagine that any reasonable production scenario where a package would be used in some essential function, then that package should be considered for this category.\nHowever, packages which we consider essential to getting a robot up and running quickly, but is a generic solution to the problem should probably not start out as ‘Level 1’.\nFor Example, the packages which provide in-process communication, interprocess communication, generated message runtime code, and component lifecycle should probably all be considered ‘Level 1’.\nHowever, a package which provides pose estimation (like robot_pose_ekf) is a generic solution something that most people need, but is often replaced with a domain specific solution in production, and therefore it should probably not start out as ‘Level 1’.\nHowever, it may upgrade to it at a later date, if it proves to be a solution that people want to use in their products.\nTools, like rostopic, generally do not fall into this category, but are not categorically excluded.\nFor example, it may be the case the tool which launches and verifies a ROS graph (something like roslaunch) may need to be considered ‘Level 1’ for use in production systems.\n\nPackage Requirements¶\nRequirements to be considered a ‘Level 1’ package:\n\nHave a strictly declared public API\nHave API documentation coverage for public symbols\nHave 100 percent branch code coverage from unit and integration tests\nHave system tests which cover any scenarios covered in documentation\nHave system tests for any corner cases encountered during testing\nMust be >= version 1.0.0\n\n\n\nChange Control Process¶\nThe change control process requires all changes, regardless of trivialness, must go through a pull request.\nThis is to ensure a complete memoranda of changes to the code base.\nIn order for a pull request to get merged:\n\nChanges must be reviewed by two reviewers\nCommits must be concise and descriptive\nAll automated tests must be run in CI on all applicable platforms (Windows, versions of Linux, OS X, ARM)\nCode coverage must stay at 100 percent\nAny changes which require updates to documentation must be made before merging\n\n\n\n\n(Level 2)¶\nThese are packages which need to be solidly developed and might be used in production environments, but are not strictly required, or are commonly replaced by custom solutions.\nThis can also include packages which are not yet up to ‘Level 1’ but intend to be in the future.\n\n\n(Level 3)¶\nThese are packages which are useful for development purposes or introspection, but are not recommended for use in embedded products or mission critical scenarios.\nThese packages are more lax on documentation, testing, and scope of public API’s in order to make development time lower or foster addition of new features.\n\n\n(Level 4)¶\nThese are demos, tutorials, or experiments.\nThey don’t have strict requirements, but are not excluded from having good documentation or tests.\nFor example, this might be a tutorial package which is not intended for reuse but has excellent documentation because it serves primarily as an example to others.\n\n\n\n"}]
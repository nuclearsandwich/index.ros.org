[{"id":36,"url":"/doc/ros2/Contributing/Set-up-a-new-macOS-CI-node/","title":"How to setup a macOS Jenkins node","content":"\nHow to setup a macOS Jenkins node¶\n\nTable of Contents\n\nInstall macOS High Sierra\nSetup SSH/VNC for Remote Access\nHost Setup\nInstall ROS 2 Dependencies\nSetting up the Jenkins Workspace and Agent\n\n\n\nNote\nLast installed/updated on 2017-11-20 (Mac OS 10.13.1 High Sierra) and see this older (private) document for previous instructions.\n\n\nInstall macOS High Sierra¶\nInstall: APFS case-sensitive\nPost-install: No Siri, no location services, no cloud anything, no analytics, no filevault disk encryption.\n\n\nSetup SSH/VNC for Remote Access¶\nMake sure you don’t use too long of a password.\nThat makes VNC auth fail in bizarre ways.\nIn particular, VNC auth limits you to 8 characters.\n\nGo to: Apple->System Preferences->Sharing\n\nset hostname to something reasonable\ncheck “Remote Login”\ncheck “Screen Sharing”\n\n\nadd Terminal to the dock\nGo to: Apple->System Preferences->Energy Saver\n\nset sleep to never\nuncheck everything\n\n\nGo to: Apple->Security\n\nclick lock to unlock it\n“Allow Apps from app store and verified developers”\nuncheck “Require password after 5 minutes” box\nuncheck “Disable automatic login”\n\n\n\n\n\nHost Setup¶\nInstall XCode tools:\n$ xcode select --install\n\n\nInstall JDK for Jenkins.\nEasiest way is to type java at the terminal and let Apple link you to Oracle’s JDK download.\nI installed the latest JDK 8 (withholding Java 9 for now).\nInstall Homebrew following instructions at https://brew.sh\nInstall ssh-askpass via homebrew\n$ brew tap theseal/ssh-askpass\n$ brew install ssh-askpass\n\n\nCreate ~/.bash_profile with this one line:\n. ~/.bashrc\n\n\nCreate ~/.bashrc with one line:\nexport ROS_DOMAIN_ID=XXX  # where XXX is chosen from this document\n\n\nSet up dummy git names:\n$ git config --global user.email \"nobody@osrfoundation.org\"\n$ git config --global user.name \"HOSTNAME\"\n\n\n\n\nInstall ROS 2 Dependencies¶\nInstall them according to our install instructions.\nIncluding:\n\nbrew packages\npip packages\nthe optional RTI Connext and OpenSplice packages\neverything but downloading the source and building ROS 2 (unless you want to do so for testing the setup)\n\n\nRQt dependencies¶\n\nbrew install sip pyqt5\nFix some path names when looking for sip stuff during install (see ROS 1 wiki):\nln -s /usr/local/share/sip/Qt5 /usr/local/share/sip/PyQt5\n\nbrew install graphviz\npython3 -m pip install pygraphviz pydot\nbrew link --force qt\nThis is the quickest solution but may cause issues when upgrading Qt or if other packages are expecting Qt 4.\nAnother option is to update your PATH and CMAKE_PREFIX_PATH to include the Qt install location:\n$ export PATH=\"$(brew --prefix qt)/bin:$PATH\"\n$ export CMAKE_PREFIX_PATH=\"$(brew --prefix qt):$CMAKE_PREFIX_PATH\"\n\n\n\n\n\n\nRTI Connext Specific Instructions¶\n\nThe Open Robotics license is here (private repo): https://github.com/osrf/rticonnextdds-src/blob/license/rti_license.dat\nOpen the RTI launcher application\n\nIn the RTI launcher, open the file dialog to choose the license file.\nInstall it for all users.\nClick the Installation tab\nClick RTI Package installer\n\n\nNavigate to the connext extracted directory (usually something like /Applications/rti_...\n\nSelect the rti_security rtipkg (don’t bother with the openssl ones, we use system openssl)\n\n\nSet the shared memory parameters from https://community.rti.com/kb/osx510\n\nDo not bother to reboot yet.\n\n\n\n\n\n\nSetting up the Jenkins Workspace and Agent¶\n$ mkdir jenkins jenkins-agent\n$ cd jenkins-agent\n$ wget http://ci.ros2.org/jnlpJars/slave.jar\n\n\nCopy the jenkins agent plist from https://gist.github.com/nuclearsandwich/c9546e76ba63767bc1025c393e85235b\nEdit the file to match the jnlp url and secret of the host you’re setting up.\nYou may need to create a new agent if you’re not re-imaging an existing one.\n$ mkdir ~/Library/LaunchAgents\n$ cp ~/jenkins-agent/org.ros2.ci.jenkins-agent.plist ~/Library/LaunchAgents\n$ launchctl load -w ~/Library/LaunchAgents/org.ros2.ci.jenkins-agent.plist\n\n\nReboot! You should be good to go, run some test CI jobs.\n\n\n"},{"id":37,"url":"/doc/ros2/Contributing/CI-Server-Setup/","title":"How to setup the Jenkins master","content":"\nHow to setup the Jenkins master¶\n\nTable of Contents\n\nInstalling\nRunning on port 80\nTemporary rewrite for changed job name\nInstall stuff (needed on master and slaves)\nAdding a Linux slave to the farm\nConfiguring Jenkins\n\nAuthentication\nPlugins\nAdding an ssh key\n\n\nCreating Jobs\n\nTuning Auto-generated Jobs\n\n\nDisk space\n\n\n\nInstalling¶\nInstall the latest LTS release from http://pkg.jenkins-ci.org/debian-stable/\n\n\nRunning on port 80¶\nI used this SO answer to setup a subdomain to a port:\nhttp://serverfault.com/a/140161/186748\nI had to remove the hudson in each of the lines that contained it.\n\n\nTemporary rewrite for changed job name¶\nWe renamed some of the jobs, so I added rewrite rules in Apache (/etc/apache2/sites-enabled/ci.ros2.org.conf):\n# Temporary rewrite rule because we changed the Windows job name.\nRewriteEngine On\nRewriteRule ^(.*)/ros2_batch_ci_linux/(.*)$ $1/ci_linux/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_osx/(.*)$ $1/ci_osx/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_windows/(.*)$ $1/ci_windows_opensplice/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_windows_opensplice/(.*)$ $1/ci_windows_opensplice/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_windows_connext_static/(.*)$ $1/ci_windows_connext_static/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_windows_connext_dynamic/(.*)$ $1/ci_windows_connext_dynamic/$2 [R=301,L]\nRewriteRule ^(.*)/ci_windows_opensplice/(.*)$ $1/ci_windows/$2 [R=301,L]\nRewriteRule ^(.*)/ci_windows_connext_static/(.*)$ $1/old_windows_connext_static/$2 [R=301,L]\nRewriteRule ^(.*)/ci_windows_connext_dynamic/(.*)$ $1/old_windows_connext_dynamic/$2 [R=301,L]\nRewriteRule ^(.*)/ci_windows_fastrtps/(.*)$ $1/old_windows_fastrtps/$2 [R=301,L]\n\nRewriteRule ^(.*)/ros2_batch_ci_linux_nightly/(.*)$ $1/nightly_linux/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_osx_nightly/(.*)$ $1/nightly_osx/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_windows_opensplice_nightly/(.*)$ $1/nightly_windows_opensplice/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_windows_connext_static_nightly/(.*)$ $1/nightly_windows_connext_static/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_batch_ci_windows_connext_dynamic_nightly/(.*)$ $1/nightly_windows_connext_dynamic/$2 [R=301,L]\nRewriteRule ^(.*)/nightly_windows_opensplice/(.*)$ $1/nightly_windows/$2 [R=301,L]\nRewriteRule ^(.*)/nightly_windows_connext_static/(.*)$ $1/old_night_windows_connext_static/$2 [R=301,L]\nRewriteRule ^(.*)/nightly_windows_connext_dynamic/(.*)$ $1/old_night_windows_connext_dynamic/$2 [R=301,L]\n\nRewriteRule ^(.*)/ros2_packaging_linux/(.*)$ $1/packaging_linux/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_packaging_osx/(.*)$ $1/packaging_osx/$2 [R=301,L]\nRewriteRule ^(.*)/ros2_packaging_windows_opensplice/(.*)$ $1/packaging_windows_opensplice/$2 [R=301,L]\nRewriteRule ^(.*)/packaging_windows_opensplice/(.*)$ $1/packaging_windows/$2 [R=301,L]\n\n\n\n\nInstall stuff (needed on master and slaves)¶\nsudo apt update\nsudo apt install -y git\n# Your java version will vary depending on your OS:\n#sudo apt install openjdk-7-jre-headless\n#sudo apt install openjdk-8-jre-headless\n# For ARM native servers, we need the tomcat native libs to support ssh-agent\n# (https://issues.jenkins-ci.org/browse/JENKINS-30746)\n#sudo apt install libtcnative-1\n# qemu and vcs are required for ARM builds\nsudo apt install -y qemu-user-static\nsudo bash -c 'echo \"deb http://repositories.ros.org/ubuntu/testing/ `lsb_release -cs` main\" > /etc/apt/sources.list.d/ros-latest.list'\nsudo bash -c 'curl --silent http://repositories.ros.org/repos.key |sudo apt-key add -'\n# Or, on aarch64:\n#sudo apt install docker.io\nsudo apt update\nsudo apt install -y python-vcstool\ncurl -fsSL https://get.docker.com/ | sh\nsudo adduser --disabled-password jenkins\nsudo usermod -aG docker jenkins\nsudo service docker start\n\n\n\n\nAdding a Linux slave to the farm¶\nApproximately:\n\nShell into the master (ci.ros2.org), copy /var/lib/jenkins/.ssh/id_rsa.pub and paste it into /home/jenkins/.ssh/authorized_keys on the new machine.\nCopy config from the linux 2 machine, rename and otherwise modify as needed (e.g., change the IP/host).\nCopy /etc/ssh/ssh_host_rsa_key.pub from the new machine and add it as an entry in /var/lib/jenkins/.ssh/known_hosts (with the new machine’s IP) on the master, then re-hash that file on the master: ssh-keygen -H.\n\n\n\nConfiguring Jenkins¶\nFirst I updated all the preinstalled plugins.\n\nAuthentication¶\nThen I setup authentication with the github-oauth plugin.\nI just installed it and followed their setup instructions:\nhttps://wiki.jenkins-ci.org/display/JENKINS/Github+OAuth+Plugin\nI created an application entry on the ros2 GitHub organization:\nhttps://github.com/organizations/ros2/settings/applications/215300\nI also tuned the permissions in Manage Jenkins->Configure Global Security.\n\n\nPlugins¶\nNext I installed all of these plugins:\n\nansicolor\ndescription-setter\ngithub (other git* plugins are deps of the github-oauth plugin)\ngreenballs\ngroovy\nparameterized-trigger\nPrioritySorter\njobrequeue\nssh-agent\nwarnings\nxunit\n\n\n\nAdding an ssh key¶\nJenkins needs a valid ssh key in order to pull from some of our private repositories, for example to get the rti deb files.\nSo I created an ssh key for the jenkins user on the webserver:\nsudo su jenkins\ncd\nmkdir .ssh\nssh-keygen -t rsa\n\n\nThen I added to the jenkins credentials as an “From the jenkins master ~/.ssh” with the user id of ros2-buildfarm.\nI added this key to a “machine” GitHub account that I created for this farm and I added that user, ros2-buildfarm, to the ros2, ament, and osrf organizations.\n\n\n\nCreating Jobs¶\nI cloned the ros2/ci repository to the default branch (master):\ngit clone https://github.com/ros2/ci.git\n\n\nThen I cloned the ros_buildfarm repository:\ngit clone https://github.com/ros-infrastructure/ros_buildfarm.git\n\n\nI also install the jenkinsapi and EmPy Python packages:\nsudo apt install python3-pip\nsudo -H python3 -m pip install -U pip\nsudo -H python3 -m pip install jenkinsapi EmPy\n\n\nThen I setup auth:\nmkdir -p ~/.buildfarm\nvim ~/.buildfarm/jenkins.ini\n\n\nPut this in the jenkins.ini file:\n[http://ci.ros2.org]\nusername=wjwwood\npassword=<your application token>\n\n\nNow, you should first login with GitHub on Jenkins if you haven’t already.\nThen put your github username in and for the application token, browse to the configuration of your user on Jenkins:\nhttp://ci.ros2.org/user/wjwwood/configure\nIn those settings there should be a field called API Token.\nCopy that field for your password.\nNow I can create the jobs:\n$ PYTHONPATH=`pwd`/../ros_buildfarm ./create_jenkins_job.py -u http://ci.ros2.org\nConnecting to Jenkins 'http://ci.ros2.org'\nConnected to Jenkins version '1.617'\nCreating job 'ros2_batch_ci_windows'\nThe Jenkins master does not require a crumb\nCreating job 'ros2_batch_ci_osx'\nCreating job 'ros2_batch_ci_linux'\nCreating job 'ros2_batch_ci_launcher'\n\n\n\nTuning Auto-generated Jobs¶\nThe final step is to fine tune the jobs.\nFor each job you’ll want to check the ssh key being used for the git clone (only on Linux) and the ssh-agent.\nIt should be set to the ssh key setup in the previous steps for the jenkins user.\nI also updated the slaves which the jobs will run on to make sure they matched the names of the slaves I added for Linux, OS X and Windows.\n\n\n\nDisk space¶\nOver time docker images and particularly containers will pile up.\nTo clean up use:\ndocker rm $(docker ps -a -q)\ndocker rmi $(docker images -q -f dangling=true)\n\n\nfrom https://www.calazan.com/docker-cleanup-commands/\n\n\n"},{"id":38,"url":"/doc/ros2/Tutorials/Allocator-Template-Tutorial/","title":"Implement a custom memory allocator","content":"\nImplement a custom memory allocator¶\n\nTable of Contents\n\nBackground\nWriting an allocator\nWriting an example main\nPassing an allocator to the intra-process pipeline\nTesting and verifying the code\nThe TLSF allocator\n\n\nThis tutorial will teach you how to integrate a custom allocator for publishers and subscribers so that the default heap allocator is never called while your ROS nodes are executing.\nThe code for this tutorial is available here.\n\nBackground¶\nSuppose you want to write real-time safe code, and you’ve heard about the many dangers of calling “new” during the real-time critical section, because the default heap allocator on most platforms is nondeterministic.\nBy default, many C++ standard library structures will implicitly allocate memory as they grow, such as std::vector. However, these data structures also accept an “Allocator” template argument. If you specify a custom allocator to one of these data structures, it will use that allocator for you instead of the system allocator to grow or shrink the data structure. Your custom allocator could have a pool of memory preallocated on the stack, which might be better suited to real-time applications.\nIn the ROS 2 C++ client library (rclcpp), we are following a similar philosophy to the C++ standard library. Publishers, subscribers, and the Executor accept an Allocator template parameter that controls allocations made by that entity during execution.\n\n\nWriting an allocator¶\nTo write an allocator compatible with ROS 2’s allocator interface, your allocator must be compatible with the C++ standard library allocator interface.\nThe C++11 library provides something called allocator_traits. The C++11 standard specifies that a custom allocator only needs to fulfil a minimal set of requirements to be used to allocate and deallocate memory in a standard way. allocator_traits is a generic structure that fills out other qualities of an allocator based on an allocator written with the minimal requirements.\nFor example, the following declaration for a custom allocator would satisfy allocator_traits (of course, you would still need to implement the declared functions in this struct):\ntemplate <class T>\nstruct custom_allocator {\n  using value_type = T;\n  custom_allocator() noexcept;\n  template <class U> custom_allocator (const custom_allocator<U>&) noexcept;\n  T* allocate (std::size_t n);\n  void deallocate (T* p, std::size_t n);\n};\n\ntemplate <class T, class U>\nconstexpr bool operator== (const custom_allocator<T>&, const custom_allocator<U>&) noexcept;\n\ntemplate <class T, class U>\nconstexpr bool operator!= (const custom_allocator<T>&, const custom_allocator<U>&) noexcept;\n\n\nYou could then access other functions and members of the allocator filled in by allocator_traits like so: std::allocator_traits<custom_allocator<T>>::construct(...)\nTo learn about the full capabilities of allocator_traits, see http://en.cppreference.com/w/cpp/memory/allocator_traits .\nHowever, some compilers that only have partial C++11 support, such as GCC 4.8, still require allocators to implement a lot of boilerplate code to work with standard library structures such as vectors and strings, because these structures do not use allocator_traits internally. Therefore, if you’re using a compiler with partial C++11 support, your allocator will need to look more like this:\ntemplate<typename T>\nstruct pointer_traits {\n  using reference = T &;\n  using const_reference = const T &;\n};\n\n// Avoid declaring a reference to void with an empty specialization\ntemplate<>\nstruct pointer_traits<void> {\n};\n\ntemplate<typename T = void>\nstruct MyAllocator : public pointer_traits<T> {\npublic:\n  using value_type = T;\n  using size_type = std::size_t;\n  using pointer = T *;\n  using const_pointer = const T *;\n  using difference_type = typename std::pointer_traits<pointer>::difference_type;\n\n  MyAllocator() noexcept;\n\n  ~MyAllocator() noexcept;\n\n  template<typename U>\n  MyAllocator(const MyAllocator<U> &) noexcept;\n\n  T * allocate(size_t size, const void * = 0);\n\n  void deallocate(T * ptr, size_t size);\n\n  template<typename U>\n  struct rebind {\n    typedef MyAllocator<U> other;\n  };\n};\n\ntemplate<typename T, typename U>\nconstexpr bool operator==(const MyAllocator<T> &,\n  const MyAllocator<U> &) noexcept;\n\ntemplate<typename T, typename U>\nconstexpr bool operator!=(const MyAllocator<T> &,\n  const MyAllocator<U> &) noexcept;\n\n\n\n\nWriting an example main¶\nOnce you have written a valid C++ allocator, you must pass it as a shared pointer to your publisher, subscriber, and executor.\nauto alloc = std::make_shared<MyAllocator<void>>();\nauto publisher = node->create_publisher<std_msgs::msg::UInt32>(\"allocator_example\", 10, alloc);\nauto msg_mem_strat =\n  std::make_shared<rclcpp::message_memory_strategy::MessageMemoryStrategy<std_msgs::msg::UInt32,\n  MyAllocator<>>>(alloc);\nauto subscriber = node->create_subscription<std_msgs::msg::UInt32>(\n  \"allocator_example\", 10, callback, nullptr, false, msg_mem_strat, alloc);\n\nstd::shared_ptr<rclcpp::memory_strategy::MemoryStrategy> memory_strategy =\n  std::make_shared<AllocatorMemoryStrategy<MyAllocator<>>>(alloc);\nrclcpp::executors::SingleThreadedExecutor executor(memory_strategy);\n\n\nYou will also need to use your allocator to allocate any messages that you pass along the execution codepath.\nauto alloc = std::make_shared<MyAllocator<void>>();\n\n\nOnce you’ve instantiated the node and added the executor to the node, it’s time to spin:\nuint32_t i = 0;\nwhile (rclcpp::ok()) {\n  msg->data = i;\n  i++;\n  publisher->publish(msg);\n  rclcpp::utilities::sleep_for(std::chrono::milliseconds(1));\n  executor.spin_some();\n}\n\n\n\n\nPassing an allocator to the intra-process pipeline¶\nEven though we instantiated a publisher and subscriber in the same process, we aren’t using the intra-process pipeline yet.\nThe IntraProcessManager is a class that is usually hidden from the user, but in order to pass a custom allocator to it we need to expose it by getting it from the rclcpp Context. The IntraProcessManager makes use of several standard library structures, so without a custom allocator it will call the default new.\nauto context = rclcpp::contexts::default_context::get_global_default_context();\nauto ipm_state =\n  std::make_shared<rclcpp::intra_process_manager::IntraProcessManagerState<MyAllocator<>>>();\n// Constructs the intra-process manager with a custom allocator.\ncontext->get_sub_context<rclcpp::intra_process_manager::IntraProcessManager>(ipm_state);\nauto node = rclcpp::Node::make_shared(\"allocator_example\", true);\n\n\nMake sure to instantiate publishers and subscribers AFTER constructing the node in this way.\n\n\nTesting and verifying the code¶\nHow do you know that your custom allocator is actually getting called?\nThe obvious thing to do would be to count the calls made to your custom allocator’s allocate and deallocate functions and compare that to the calls to new and delete.\nAdding counting to the custom allocator is easy:\nT * allocate(size_t size, const void * = 0) {\n  // ...\n  num_allocs++;\n  // ...\n}\n\nvoid deallocate(T * ptr, size_t size) {\n  // ...\n  num_deallocs++;\n  // ...\n}\n\n\nYou can also override the global new and delete operators:\nvoid operator delete(void * ptr) noexcept {\n  if (ptr != nullptr) {\n    if (is_running) {\n      global_runtime_deallocs++;\n    }\n    std::free(ptr);\n    ptr = nullptr;\n  }\n}\n\nvoid operator delete(void * ptr, size_t) noexcept {\n  if (ptr != nullptr) {\n    if (is_running) {\n      global_runtime_deallocs++;\n    }\n    std::free(ptr);\n    ptr = nullptr;\n  }\n}\n\n\nwhere the variables we are incrementing are just global static integers, and is_running is a global static boolean that gets toggled right before the call to spin.\nThe example executable prints the value of the variables. To run the example executable, use:\nallocator_example\n\n\nor, to run the example with the intra-process pipeline on:\nallocator_example intra-process\n\n\nYou should get numbers like:\nGlobal new was called 15590 times during spin\nGlobal delete was called 15590 times during spin\nAllocator new was called 27284 times during spin\nAllocator delete was called 27281 times during spin\n\n\nWe’ve caught about 2/3 of the allocations/deallocations that happen on the execution path, but where do the remaining 1/3 come from?\nAs a matter of fact, these allocations/deallocations originate in the underlying DDS implementation used in this example.\nProving this is out of the scope of this tutorial, but you can check out the test for the allocation path that gets run as part of the ROS 2 continuous integration testing, which backtraces through the code and figures out whether certain function calls originate in the rmw implementation or in a DDS implementation:\nhttps://github.com/ros2/realtime_support/blob/master/tlsf_cpp/test/test_tlsf.cpp#L41\nNote that this test is not using the custom allocator we just created, but the TLSF allocator (see below).\n\n\nThe TLSF allocator¶\nROS 2 offers support for the TLSF (Two Level Segregate Fit) allocator, which was designed to meet real-time requirements:\nhttps://github.com/ros2/realtime_support/tree/master/tlsf_cpp\nFor more information about TLSF, see http://www.gii.upv.es/tlsf/\nNote that the TLSF allocator is licensed under a dual-GPL/LGPL license.\nA full working example using the TLSF allocator is here:\nhttps://github.com/ros2/realtime_support/blob/master/tlsf_cpp/example/allocator_example.cpp\n\n\n"},{"id":39,"url":"/doc/ros2/Installation/Install-Connext-Security-Plugins/","title":"Installing Connext security plugins","content":"\nInstalling Connext security plugins¶\nThe Connext DDS Libraries are included with ROS2 under a non-commercial\nlicense and do not include the security\nplug-in libraries. These libraries are available in the commercial,\nuniversity and research license versions of RTI Connext DDS Pro, which\nis bundled with tools for system debugging, monitoring, record/replay,\netc.\nA video walk-thru of this installation (tools and security plug-ins) is\navailable\nhere at\nthe RTI website. The steps are:\nInstall Connext DDS Pro (Host)\nThis is a host-specific installer application (for Windows, Linux, MacOS) to install a ‘Host’ bundle which includes the Launcher, tools, and other software services.\nAt the end of the installation, the RTI ‘Launcher’ program will be started.\nThe Launcher is used to install target libraries, security plugins, and other layered services.\nUse the Package Installer in Launcher\n\n\nLauncher Image¶\n\nThe ‘RTI Package Installer’ is used to install ‘.rtipkg’ files – target\nlibraries, security plug-ins, etc. Open the Package Installer and select\nall of the .rtipkg files that were included in the Connext DDS Secure\nbundle for installation:\n\n\nTarget Libraries - such as: rti_connext_dds-[version]-pro-target-[toolchain].rtipkg\nSecurity Plugin Host - such as: rti_security_plugins-[version]-host-[toolchain].rtipkg\nSecurity Plugin Target - such as: rti_security_plugins-[version]-target-[toolchain].rtipkg\nOpenSSL Host - such as: openssl-1.0.2x-[version]-host-[toolchain].rtipkg\n\n\nExtract and Install OpenSSL\nThis is included as an archive (.zip or\notherwise) and can be simply extracted and copied to a convenient\nlocation on your host computer. As a suggestion, this could also be\ninstalled into the ‘rti_connext_dds-[version]’ directory in your home\ndirectory space (this was created during installation of the RTI host\ntools). Note: this directory location may need to be placed in your PATH\nenvironment variable.\nInstallation complete.\n\n"}]
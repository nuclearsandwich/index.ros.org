[{"id":36,"url":"/doc/ros2/Contributing/Developer-Guide/","title":"ROS 2 Developer Guide","content":"\nROS 2 Developer Guide¶\n\nTable of Contents\n\nGeneral Principles\nGeneral Practices\nIssues\nPull requests\nDevelopment Process\nChanges to RMW API\nkanban board (waffle.io)\nProgramming conventions\n\n\nLanguage Versions and Code Format\nC\nC++\nPython\nCMake\nMarkdown\nJavascript\n\n\nTesting\nTest Coverage\n\n\nVersioning\nFilesystem Layout\nPackage layout\nRepository layout\n\n\nDocumentation\nPackage Categories\n(Level 1)\n(Level 2)\n(Level 3)\n(Level 4)\n\n\n\n\nThis page defines the practices and policies we employ when developing ROS 2.\n\nGeneral Principles¶\nSome principles are common to all ROS 2 development:\n\nShared ownership: Everybody working on ROS2 should feel ownership over all parts of the system.\nThe original author of a chunk of code does not have any special permission or obligation to control or maintain that chunk of code.\nEveryone is free to propose changes anywhere, to handle any type of ticket, and to review any pull request.\nBe willing to work on anything: As a corollary to shared ownership, everybody should be willing to take on any available task and contribute to any aspect of the system.\nAsk for help: If you run into trouble on something, ask your fellow developers for help, via tickets, comments, or email, as appropriate.\n\n\n\nGeneral Practices¶\nSome practices are common to all ROS 2 development:\n\nIssues¶\nWhen filing an issue please make sure to:\n\nInclude enough information for another person to understand the issue.\nIn ROS 2, the following points are needed for narrowing down the cause of an issue. Testing with as many alternatives in each category as feasible will be especially helpful.\n- The operating system and version. Reasoning: ROS 2 supports multiple platforms, and some bugs are specific to particular versions of operating systems/compilers.\n- The installation method. Reasoning: Some issues only manifest if ROS 2 has been installed from “fat archives” or from Debians. This can help us determine if the issue is with the packaging process.\n- The specific version of ROS 2. Reasoning: Some bugs may be present in a particular ROS 2 release and later fixed. It is important to know if your installation includes these fixes.\n- The DDS/RMW implementation being used (see this page for how to determine which one). Reasoning: Communication issues may be specific to the underlying ROS middleware being used.\n- The ROS 2 client library being used. Reasoning: This helps us narrow down the layer in the stack at which the issue might be.\nInclude a list of steps to reproduce the issue.\nIn case of a bug consider to provide a short, self contained, correct (compilable), example. Issues are much more likely to be resolved if others can reproduce them easily.\nMention troubleshooting steps that have been tried already, including:\n- Upgrading to the latest version of the code, which may include bug fixes that have not been released yet. See this section and follow the instructions to get the “master” branches.\n- Trying with a different RMW implementation. See this page for how to do that.\n\n\n\nPull requests¶\n\nA pull request should only focus on one change.\nSeparate changes should go into separate pull requests.\nSee GitHub’s guide to writing the perfect pull request.\nA patch should be minimal in size and avoid any kind of unnecessary changes.\nAlways run CI jobs for all platforms for every pull request and include links to jobs in the pull request.\n(If you don’t have access to the Jenkins job someone will trigger the jobs for you.)\nBefore merging a pull request all changes should be squashed into a small number of semantic commits to keep the history clear.\nBut avoid squashing commits while a pull request is under review.\nYour reviewers might not notice that you made the change, thereby introducing potential for confusion.\nPlus, you’re going to squash before merging anyway; there’s no benefit to doing it early.\n\n\nA minimum of 1 +1 from a fellow developer is required to consider a pull request to be approved, which is required before merging.\nAny developer is welcome to review and approve a pull request (see General Principles).\nWhen you start reviewing a pull request, comment on the pull request so that other developers know that you’re reviewing it.\nPull-request review is not read-only, with the reviewer making comments and then waiting for the author to address them.\nAs a reviewer, feel free to make minor improvements (typos, style issues, etc.) in-place.\nAs the opener of a pull-request, if you are working in a fork, checking the box to allow edits from upstream contributors will assist with the aforementioned.\nAs a reviewer, also feel free to make more substantial improvements, but consider putting them in a separate branch (either mention the new branch in a comment, or open another pull request from the new branch to the original branch).\nAny developer (the author, the reviewer, or somebody else) can merge any approved pull request.\n\n\n\nDevelopment Process¶\n\nThe default branch (in most cases the master branch) must always build, pass all tests and compile without warnings.\nIf at any time there is a regression it is the top priority to restore at least the previous state.\nAlways build with tests enabled.\nAlways run tests locally after changes and before proposing them in a pull request.\nBesides using automated tests, also run the modified code path manually to ensure that the patch works as intended.\nAlways run CI jobs for all platforms for every pull request and include links to the jobs in the pull request.\n\n\n\nChanges to RMW API¶\nWhen updating RMW API, it is required that RMW implementations for the Tier 1 middleware libraries are updated as well.\nFor example, a new function rmw_foo() introduced to the RMW API must be implemented in the following packages (as of ROS Crystal):\n\nrmw_fastrtps\nrmw_connext\n\nUpdates for non-Tier 1 middleware libraries should also be considered if feasible (e.g. depending on the size of the change).\nSee REP-2000 for the list of middleware libraries and their tiers.\n\n\nkanban board (waffle.io)¶\nTo help organize the work, the core ROS 2 development team is using a kanban system hosted at waffle.io: ROS 2 kanban.\nThis board augments the capabilities of GitHub by using labels to give a custom view into issues and pull requests across multiple repositories.\nThe data produced and edited via waffle.io are stored in the underlying GitHub objects, so there’s no requirement to use waffle.io (or for the core team to be tied to it); it just provides a useful perspective on things.\nHere’s how we’re using the columns in the board:\n\nBacklog: cards (issues) that nobody is yet working on.\nTheir order in the backlog is an approximate indicator of priority, with cards higher in the column having higher priority.\nReady: cards on which work will be started very soon.\nCards in this column should have an owner assigned.\nCards should not sit in this column for more than a few days.\nIn Progress: cards on which work is currently in progress.\nCards in this column must have an owner assigned.\nCards should not sit in this column for more than a week.\nWhen it is determined that a card will take longer, break it up into multiple cards and put the extras in the backlog.\nIn Review: cards for which the work is done and the relevant pull request/s is/are ready for review.\nCards remain in this column during review, but if review uncovers significant extra work to be done, move the card into an earlier column as appropriate.\nDone: cards for which the work is done, meaning that the relevant pull request/s has/have been merged.\nThis column shows recently completed cards, for informational purposes only.\n\nTips for working with the kanban board:\n\nRequesting permission to make changes. Simply comment on specific tickets that you want to work on it. Depending on the complexity it might be useful to describe how you want to address it. We will update the status (if you don’t have the permission) and you can start working on a pull request. If you contribute regularly we will likely just grant you permission to manage the labels etc. yourself.\nUsing markup to connect issues and pull requests (see the waffle.io FAQ).\nDoing equivalent things outside waffle.io, directly via GitHub. The column a card is in is determined by the label. The first and last column do not require a specific label. For the other column a label with the same name can be assigned.\n\n\n\nProgramming conventions¶\n\nDefensive programming: ensure that assumptions are held as early as possible.\nE.g. check every return code and make sure to at least throw an exception until the case is handled more gracefully.\nAll error messages must be directed to stderr.\nDeclare variables in the narrowest scope possible.\nKeep group of items (dependencies, imports, includes, etc.) ordered alphabetically.\n\n\nC++ specific¶\n\nAvoid using direct streaming (<<) to stdout / stderr to prevent interleaving between multiple threads.\nAvoid using references for std::shared_ptr since that subverts the reference counting. If the original instance goes out of scope and the reference is being used it accesses freed memory.\n\n\n\n\n\nLanguage Versions and Code Format¶\nIn order to achieve a consistent looking product we will all follow externally (if possible) defined style guidelines for each language.\nFor other things like package layout or documentation layout we will need to come up with our own guidelines, drawing on current, popular styles in use now.\nAdditionally, where ever possible, developers should use integrated tools to allow them to check that these guidelines are followed in their editors.\nFor example, everyone should have a PEP8 checker built into their editor to cut down on review iterations related to style.\nAlso where possible, packages should check style as part of their unit tests to help with the automated detection of style issues (see ament_lint_auto).\n\nC¶\n\nStandard¶\nWe will target C99.\n\n\nStyle¶\nWe will use Python’s PEP7 for our C style guide, with some modifications and additions:\n\nWe will target C99, as we do not need to support C89 (as PEP7 recommends)\nrationale: among other things it allows us to use both // and /* */ style comments\nrationale: C99 is pretty much ubiquitous now\n\n\nC++ style // comments are allowed\nAlways place literals on the left hand side of comparison operators, e.g. 0 == ret instead of ret == 0\nrationale: ret == 0 too easily turns into ret = 0 by accident\n\n\n\nAll of the following modifications only apply if we are not writing Python modules:\n\nDo not use Py_ as a prefix for everything\ninstead use a CamelCase version of the package name or other appropriate prefix\n\n\nThe stuff about documentation strings doesn’t apply\n\nWe can use the pep7 python module for style checking. The editor integration seems slim, we may need to look into automated checking for C in more detail.\n\n\n\nC++¶\n\nStandard¶\nWe will target C++14, using new built-in C++14 features over Boost equivalents where ever possible.\n\n\nStyle¶\nWe will use the Google C++ Style Guide, with some modifications:\n\nLine Length¶\n\nOur maximum line length is 100 characters.\n\n\n\nVariable Naming¶\n\nFor global variables use lowercase with underscores prefixed with g_\nrationale: keep variable naming case consistent across the project\nrationale: easy to tell the scope of a variable at a glance\nconsistency across languages\n\n\n\n\n\nFunction and Method Naming¶\n\nGoogle style guide says CamelCase, but the C++ std library’s style of snake_case is also allowed\nrationale: ROS 2 core packages currently use snake_case\nreason: either an historical oversight or a personal preference that didn’t get checked by the linter\nreason for not changing: retroactively changing would be too disruptive\n\n\nother considerations:\ncpplint.py does not check this case (hard to enforce other than with review)\nsnake_case can result in more consistency across languages\n\n\nspecific guidance:\nfor existing projects, prefer the existing style\nfor new projects, either is acceptable, but a preference for matching related existing projects is advised\nfinal decision is always developer discretion\nspecial cases like function pointers, callable types, etc. may require bending the rules\n\n\nNote that classes should still use CamelCase by default\n\n\n\n\n\n\n\nAccess Control¶\n\nDrop requirement for all class members to be private and therefore require accessors\nrationale: this is overly constraining for user API design\nwe should prefer private members, only making them public when they are needed\nwe should consider using accessors before choosing to allow direct member access\nwe should have a good reason for allowing direct member access, other than because it is convenient for us\n\n\n\n\n\nExceptions¶\n\nExceptions are allowed\nrationale: this is a new code base, so the legacy argument doesn’t apply to us\nrationale: for user facing API’s it is more idiomatic C++ to have exceptions\nExceptions in destructors should be explicitly avoided\n\n\nWe should consider avoiding Exceptions if we intend to wrap the resulting API in C\nrationale: it will make it easier to wrap in C\nrationale: most of our dependencies in code we intend to wrap in C do not use exceptions anyways\n\n\n\n\n\nFunction-like Objects¶\n\nNo restrictions on Lambda’s or std::function or std::bind\n\n\n\nBoost¶\n\nBoost should be avoided until absolutely required\n\n\n\nComments and Doc Comments¶\n\nUse /// and /** */ comments for documentation purposes and // style comments for notes and general comments\nClass and Function comments should use /// and /** */ style comments\nrationale: these are recommended for Doxygen and Sphinx in C/C++\nrationale: mixing /* */ and // is convenient for block commenting out code which contains comments\nDescriptions of how the code works or notes within classes and functions should use // style comments\n\n\n\n\n\nPointer Syntax Alignment¶\n\nUse char * c; instead of char* c; or char *c; because of this scenario char* c, *d, *e;\n\n\n\nClass Privacy Keywords¶\n\nDo not put 1 space before public:, private:, or protected:, it is more consistent for all indentions to be a multiple of 2\nrationale: most editors don’t like indentions which are not a multiple of the (soft) tab size\nUse zero spaces before public:, private:, or protected:, or 2 spaces\nIf you use 2 spaces before, indent other class statements by 2 additional spaces\nPrefer zero spaces, i.e. public:, private:, or protected: in the same column as the class\n\n\n\n\n\nNested Templates¶\n\nNever add whitespace to nested templates\nPrefer set<list<string>> (C++11 feature) to set<list<string> > or set< list<string> >\n\n\n\n\n\nAlways Use Braces¶\n\nAlways use braces following if, else, do, while, and for, even when the body is a single line.\nrationale: less opportunity for visual ambiguity and for complications due to use of macros in the body\n\n\n\n\n\nOpen Versus Cuddled Braces¶\n\nUse open braces for function, class, and struct definitions, but cuddle braces on if, else, while, for, etc...\nException: when an if (or while, etc.) condition is long enough to require line-wrapping, then use an open brace (i.e., don’t cuddle).\n\n\nWhen a function call cannot fit on one line, wrap at the open parenthesis (not in between arguments) and start them on the next line with a 2-space indent.  Continue with the 2-space indent on subsequent lines for more arguments.  (Note that the Google style guide is internally contradictory on this point.)\nSame goes for if (and while, etc.) conditions that are too long to fit on one line.\n\n\n\n\n\nExamples¶\nThis is OK:\nint main(int argc, char **argv)\n{\n  if (condition) {\n    return 0;\n  } else {\n    return 1;\n  }\n}\n\nif (this && that || both) {\n  ...\n}\n\n// Long condition; open brace\nif (\n  this && that || both && this && that || both && this && that || both && this && that)\n{\n  ...\n}\n\n// Short function call\ncall_func(foo, bar);\n\n// Long function call; wrap at the open parenthesis\ncall_func(\n  foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar,\n  foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar, foo, bar);\n\n// Very long function argument; separate it for readability\ncall_func(\n  bang,\n  fooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo,\n  bar, bat);\n\n\nThis is not OK:\nint main(int argc, char **argv) {\n  return 0;\n}\n\nif (this &&\n    that ||\n    both) {\n  ...\n}\n\n\nUse open braces rather than excessive indention, e.g. for distinguishing constructor code from constructor initializer lists\nThis is OK:\nReturnType LongClassName::ReallyReallyReallyLongFunctionName(\n  Type par_name1,  // 2 space indent\n  Type par_name2,\n  Type par_name3)\n{\n  DoSomething();  // 2 space indent\n  ...\n}\n\nMyClass::MyClass(int var)\n: some_var_(var),\n  some_other_var_(var + 1)\n{\n  ...\n  DoSomething();\n  ...\n}\n\n\nThis is not OK, even weird (the google way?):\nReturnType LongClassName::ReallyReallyReallyLongFunctionName(\n    Type par_name1,  // 4 space indent\n    Type par_name2,\n    Type par_name3) {\n  DoSomething();  // 2 space indent\n  ...\n}\n\nMyClass::MyClass(int var)\n    : some_var_(var),             // 4 space indent\n      some_other_var_(var + 1) {  // lined up\n  ...\n  DoSomething();\n  ...\n}\n\n\n\n\nLinters¶\nMost of these styles and restrictions can be checked with a combination of Google’s cpplint.py and uncrustify, though we may need to modify them slightly for our above changes.\nWe provide command line tools with custom configurations:\n\nament_cpplint\nament_uncrustify: configuration\n\nWe also run other tools to detect and eliminate as many warnings as possible.\nHere’s a non-exhaustive list of additional things we try to do on all of our packages:\n\nuse compiler flags like -Wall -Wextra -Wpedantic\nrun static code analysis like cppcheck, which we have integrated in ament_cppcheck.\n\n\n\n\n\nPython¶\n\nVersion¶\nWe will target Python 3 for our development.\n\n\nStyle¶\nWe will use the PEP8 guidelines for code format.\nWe chose the following more precise rule where PEP 8 leaves some freedom:\n\nWe allow up to 100 character per line (fifth paragraph).\nWe pick single quotes over double quotes as long as no escaping is necessary.\n\nTools like the (ament_)pep8 Python package should be used in unit-test and/or editor integration for checking Python code style.\nThe pep8 configuration used in the linter is here.\nIntegration with editors:\n\natom: https://atom.io/packages/linter-pep8\nemacs: http://kwbeam.com/emacs-for-python-i.html\nSublime Text: https://sublime.wbond.net/packages/SublimeLinter-flake8\nvim: https://github.com/nvie/vim-flake8\n\n\n\n\nCMake¶\n\nVersion¶\nWe will target CMake 3.5.\n\n\nStyle¶\nSince there is not an existing CMake style guide we will define our own:\n\nUse lowercase keywords (functions and macros).\nUse empty else() and end...() commands.\nNo whitespace before (‘s.\nUse two spaces of indention, do not use tabs.\nDo not use aligned indentation for parameters of multi-line macro invocations. Use two spaces only.\nPrefer functions with set(PARENT_SCOPE) to macros.\nWhen using macros prefix local variables with _ or a reasonable prefix.\n\n\n\n\nMarkdown¶\n\nStyle¶\nThe following rules to format the markdown syntax is intended to increase readability as well as versioning.\n\nEach section title should be preceded by one empty line and succeeded by one empty line.\nRationale: It expedites to get an overview about the structure when screening the document.\n\n\nEach sentence must start on a new line.\nRationale: For longer paragraphs a single change in the beginning makes the diff unreadable since it carries forward through the whole paragraph.\n\n\nEach sentence can optionally be wrapped to keep each line short.\nThe lines should not have any trailing white spaces.\nA code block must be preceded and succeeded by an empty line.\nRationale: Whitespace is significant only directly before and directly after fenced code blocks.\nFollowing these instructions will ensure that highlighting works properly and consistently.\n\n\nA code block should specify a syntax after the opening triple backticks.\n\n\n\n\nJavascript¶\n(Speculative, not yet used)\n\nVersion¶\nWe will target Javascript 1.5, which seems to provide the best balance of support in browsers and languages (node.js) and new features.\n\n\nStyle¶\nWe will use the airbnb Javascript Style guide.\nThe repository referred to above comes with a jshintrc file which allows the style to be enforced using jshint.\nEditor integration for jshint include vim, emacs, Sublime Text, and others can be found here.\n\n\n\n\nTesting¶\nAll packages should have some level of tests.\nTests can be broken down into three main categories: System tests, Integration tests, and Unit tests.\nUnit tests should always be in the package which is being tested and should make use of tools like Mock to try and test narrow parts of the code base in constructed scenarios.\nUnit tests should not bring in test dependencies that are not testing tools, e.g. gtest, nosetest, pytest, mock, etc...\nIntegration tests can test interactions between parts of the code or between parts of the code and the system.\nThey often test software interfaces in ways that we expect the user to use them.\nLike Unit tests, Integration tests should be in the package which is being tested and should not bring in non-tool test dependencies unless absolutely necessary, i.e. all non-tool dependencies should only be allowed under extreme scrutiny so they should be avoided if possible.\nSystem tests are designed to test end-to-end situations between packages and should be in their own packages to avoid bloating or coupling packages and to avoid circular dependencies.\nIn general minimizing external or cross package test dependencies should be avoided to prevent circular dependencies and tightly coupled test packages.\nAll packages should have some unit tests and possibly integration tests, but the degree to which they should have them is based on the package’s category (described later).\n\nTest Coverage¶\nSome packages should have a mechanism setup to capture test coverage information (if applicable to the language).\nCoverage tools exist for some of the languages described here including C, C++, and Python, but possibly others.\nWhen possible coverage should be measured in terms of branch coverage, as opposed to statement or function coverage.\n\n\n\nVersioning¶\n(Planned; not yet used)\nWe will use the Semantic Versioning guidelines for versioning.\nAnything below version 1.0.0 is free to make changes at will and for most of our near-term development this will be the case.\nIn general though for versions less than 1.0.0 we should increment the minor (as major.minor.patch) when we break existing API and increment patch for anything else.\nAnother part of adhering to the Semantic Versioning guidelines is that every package must declare a public API.\nThe declaration for most C and C++ packages is simple, it is any header that it installs, but it is acceptable to define a set of symbols which are considered private.\nWhen ever possible having private symbols in public headers should be avoided.\nFor other languages like Python, a public API must be explicitly defined, so that it is clear what symbols can be relied on with respect to the versioning guidelines.\nThe public API can also be extended to build artifacts like configuration variables, CMake config files, etc. as well as executables and command line options and output.\nAny elements of the public API should be clearly stated in the package’s documentation.\nIf something you are using is not explicitly listed as part of the public API in the package’s documentation, then you cannot depend on it not changing between minor or patch versions.\nWith respect to library versioning, we will version all libraries within a package together.\nThis means that libraries inherit their version from the package.\nThis keeps library and package versions from diverging and shares reasoning with the policy of releasing packages which share a repository together.\nIf you need libraries to have different versions then consider splitting them into different packages.\n\n\nFilesystem Layout¶\nThe filesystem layout of packages and repositories should follow the same conventions in order to provide a consistent experience for users browsing our source code.\n\nPackage layout¶\n\nsrc: contains all C and C++ code\nAlso contains C/C++ headers which are not installed\n\n\ninclude: contains all C and C++ headers which are installed\n<package name>: for all C and C++ installed headers they should be folder namespaced by the package name\n\n\n<package_name>: contains all Python code\ntest: contains all automated tests and test data\ndoc: contains all the documentation\npackage.xml: as defined by REP-0140 (may be updated for prototyping)\nCMakeLists.txt: only ROS packages which use CMake\nsetup.py: only ROS packages which use Python code only\nREADME: README which can be rendered on Github as a landing page for the project\nThis can be as short or detailed as is convenient, but it should at least link to project documentation\nConsider putting a CI or code coverage tag in this readme\nIt can also be .rst or anything else that Github supports\n\n\nLICENSE: A copy of the license or licenses for this package\nCHANGELOG.rst: REP-0132 compliant changelog\n\n\n\nRepository layout¶\nEach package should be in a subfolder which has the same name as the package.\nIf a repository contains only a single package it can optionally be in the root of the repository.\nThe root of the repository should have a CONTRIBUTING file describing the contribution guidelines.\nThis might include license implication when using e.g. the Apache 2 License.\n\n\n\nDocumentation¶\n(API docs are not yet being automatically generated)\nAll packages should have these documentation elements:\n\nDescription and purpose\nDefinition and description of the public API\nExamples\nHow to build and install (should reference external tools/workflows)\nHow to build and run tests\nHow to build documentation\nHow to develop (useful for describing things like python setup.py develop)\n\nEach package should describe itself and its purpose or how it is used in the larger scope.\nThe description should be written, as much as possible, assuming that the reader has stumbled onto it without previous knowledge of ROS or other related projects.\nEach package should define and describe its public API so that there is a reasonable expectation for users what is covered by the semantic versioning policy.\nEven in C and C++, where the public API can be enforced by API and ABI checking, it is a good opportunity to describe the layout of the code and the function of each part of the code.\nIt should be easy to take any package and from that package’s documentation understand how to build, run, build and run tests, and build the documentation.\nObviously we should avoid repeating ourselves for common workflows, like build a package in a workspace, but the basic workflows should be either described or referenced.\nFinally, it should include any documentation for developers.\nThis might include workflows for testing the code using something like python setup.py develop, or it might mean describing how to make use of extension points provided by you package.\nExamples:\n\ncapabilities: http://docs.ros.org/hydro/api/capabilities/html/\nThis one gives an example of docs which describe the public API\n\n\ncatkin_tools: https://catkin-tools.readthedocs.org/en/latest/development/extending_the_catkin_command.html\nThis is an example of describing an extension point for a package\n\n\n\n\n\nPackage Categories¶\n(Planned; not yet used)\nThe policies will apply differently to packages depending on their categorization.\nThe categories are meant to give some expectation as to the quality of a package and allows us to be more strict or compliant with some packages and less so with others.\n\n(Level 1)¶\nThis category should be used for packages which are required for a reasonable ROS system in a production environment.\nThat is to say that after you remove development tools, build tools, and introspection tools, these packages are still left over as requirements for a basic ROS system to run.\nHowever, just because you can conceive a system which does not need a particular package does not mean that it shouldn’t be called ‘Level 1’, in fact the opposite is true.\nIf we can imagine that any reasonable production scenario where a package would be used in some essential function, then that package should be considered for this category.\nHowever, packages which we consider essential to getting a robot up and running quickly, but is a generic solution to the problem should probably not start out as ‘Level 1’.\nFor Example, the packages which provide in-process communication, interprocess communication, generated message runtime code, and component lifecycle should probably all be considered ‘Level 1’.\nHowever, a package which provides pose estimation (like robot_pose_ekf) is a generic solution something that most people need, but is often replaced with a domain specific solution in production, and therefore it should probably not start out as ‘Level 1’.\nHowever, it may upgrade to it at a later date, if it proves to be a solution that people want to use in their products.\nTools, like rostopic, generally do not fall into this category, but are not categorically excluded.\nFor example, it may be the case the tool which launches and verifies a ROS graph (something like roslaunch) may need to be considered ‘Level 1’ for use in production systems.\n\nPackage Requirements¶\nRequirements to be considered a ‘Level 1’ package:\n\nHave a strictly declared public API\nHave API documentation coverage for public symbols\nHave 100 percent branch code coverage from unit and integration tests\nHave system tests which cover any scenarios covered in documentation\nHave system tests for any corner cases encountered during testing\nMust be >= version 1.0.0\n\n\n\nChange Control Process¶\nThe change control process requires all changes, regardless of trivialness, must go through a pull request.\nThis is to ensure a complete memoranda of changes to the code base.\nIn order for a pull request to get merged:\n\nChanges must be reviewed by two reviewers\nCommits must be concise and descriptive\nAll automated tests must be run in CI on all applicable platforms (Windows, versions of Linux, OS X, ARM)\nCode coverage must stay at 100 percent\nAny changes which require updates to documentation must be made before merging\n\n\n\n\n(Level 2)¶\nThese are packages which need to be solidly developed and might be used in production environments, but are not strictly required, or are commonly replaced by custom solutions.\nThis can also include packages which are not yet up to ‘Level 1’ but intend to be in the future.\n\n\n(Level 3)¶\nThese are packages which are useful for development purposes or introspection, but are not recommended for use in embedded products or mission critical scenarios.\nThese packages are more lax on documentation, testing, and scope of public API’s in order to make development time lower or foster addition of new features.\n\n\n(Level 4)¶\nThese are demos, tutorials, or experiments.\nThey don’t have strict requirements, but are not excluded from having good documentation or tests.\nFor example, this might be a tutorial package which is not intended for reuse but has excellent documentation because it serves primarily as an example to others.\n\n\n\n"},{"id":37,"url":"/doc/ros2/Concepts/About-ROS-Interfaces/","title":"About ROS 2 Interfaces","content":"\nAbout ROS 2 Interfaces¶\n\nTable of Contents\n\n1. Background\n2. Message Description Specification\n2.1 Fields\n2.1.1 Field Types\n2.1.2 Field Names\n2.1.3 Field Default Value\n\n\n2.2 Constants\n\n\n3. Service Description Specification\n\n\n\n1. Background¶\nROS applications typically communicate through interfaces of one of two types: messages and services.\nROS uses a simplified description language to describe these interfaces. This description makes it easy for ROS tools to automatically generate source code for the interface type in several target languages.\nIn this document we will describe the supported types and how to create your own msg/srv files.\n\n\n2. Message Description Specification¶\nMessages description are defined in .msg files in the msg/ directory of a ROS package.\n.msg files are composed of two parts: fields and constants.\n\n2.1 Fields¶\nEach field consists of a type and a name, separated by a space, i.e:\nfieldtype1 fieldname1\nfieldtype2 fieldname2\nfieldtype3 fieldname3\n\n\nFor example:\nint32 my_int\nstring my_string\n\n\n\n2.1.1 Field Types¶\nField types can be:\n\na built-in-type\nnames of Message descriptions defined on their own, such as “geometry_msgs/PoseStamped”\n\nBuilt-in-types currently supported:\n\n\n\n\n\n\n\n\nType name\nC++\nPython\nDDS type\n\n\n\nbool\nbool\nbuiltins.bool\nboolean\n\nbyte\nuint8_t\nbuiltins.bytes*\noctet\n\nchar\nchar\nbuiltins.str*\nchar\n\nfloat32\nfloat\nbuiltins.float*\nfloat\n\nfloat64\ndouble\nbuiltins.float*\ndouble\n\nint8\nint8_t\nbuiltins.int*\noctet\n\nuint8\nuint8_t\nbuiltins.int*\noctet\n\nint16\nint16_t\nbuiltins.int*\nshort\n\nuint16\nuint16_t\nbuiltins.int*\nunsigned short\n\nint32\nint32_t\nbuiltins.int*\nlong\n\nuint32\nuint32_t\nbuiltins.int*\nunsigned long\n\nint64\nint64_t\nbuiltins.int*\nlong long\n\nuint64\nuint64_t\nbuiltins.int*\nunsigned long long\n\nstring\nstd::string\nbuiltins.str\nstring\n\n\n\nEvery built-in-type can be used to define arrays:\n\n\n\n\n\n\n\n\nType name\nC++\nPython\nDDS type\n\n\n\nstatic array\nstd::array<T, N>\nbuiltins.list*\nT[N]\n\nunbounded dynamic array\nstd::vector\nbuiltins.list\nsequence\n\nbounded dynamic array\ncustom_class<T, N>\nbuiltins.list*\nsequence<T, N>\n\nbounded string\nstd::string\nbuiltins.str*\nstring\n\n\n\nAll types that are more permissive than their ROS definition enforce the ROS constraints in range and length by software\nExample of message definition using arrays and bounded types:\nint32[] unbounded_integer_array\nint32[5] five_integers_array\nint32[<=5] up_to_five_integers_array\n\nstring string_of_unbounded_size\nstring<=10 up_to_ten_characters_string\n\nstring[<=5] up_to_five_unbounded_strings\nstring<=10[] unbounded_array_of_string_up_to_ten_characters each\nstring<=10[<=5] up_to_five_strings_up_to_ten_characters_each\n\n\n\n\n2.1.2 Field Names¶\nField names must be lowercase alphanumeric characters with underscores for separating words. They must start with an alphabetic character, they must not end with an underscore and never have two consecutive underscores.\n\n\n2.1.3 Field Default Value¶\nDefault values can be set to any field in the message type.\nCurrently default values are not supported for string arrays and complex types (i.e. types not present in the built-in-types table above, that applies to all nested messages)\nDefining a default value is done by adding a third element to the field definition line, i.e:\nfieldtype fieldname fielddefaultvalue\n\n\nFor example:\nuint8 x 42\nint16 y -2000\nstring full_name \"John Doe\"\nint32[] samples [-200, -100, 0, 100, 200]\n\n\nNote:\n\nstring values must be defined in single ' or double quotes \"\ncurrently string values are not escaped\n\n\n\n\n2.2 Constants¶\nEach constant definition is like a field description with a default value, except that this value can never be changed programatically. This value assignment is indicated by use of an equal ‘=’ sign, e.g.\nconstanttype CONSTANTNAME=constantvalue\n\n\nFor example:\nint32 X=123\nint32 Y=-123\nstring FOO=\"foo\"\nstring EXAMPLE='bar'\n\n\n\nNote\nConstants names have to be UPPERCASE\n\n\n\n\n3. Service Description Specification¶\nServices description are defined in .srv files in the srv/ directory of a ROS package.\nA service description file consists of a request and a response msg type, separated by ‘—’. Any two .msg files concatenated together with a ‘—’ are a legal service description.\nHere is a very simple example of a service that takes in a string and returns a string:\nstring str\n---\nstring str\n\n\nWe can of course get much more complicated (if you want to refer to a message from the same package you must not mention the package name):\n#request constants\nint8 FOO=1\nint8 BAR=2\n#request fields\nint8 foobar\nanother_pkg/AnotherMessage msg\n---\n#response constants\nuint32 SECRET=123456\n#response fields\nanother_pkg/YetAnotherMessage val\nCustomMessageDefinedInThisPackage value\nuint32 an_integer\n\n\nYou cannot embed another service inside of a service.\n\n\n"},{"id":38,"url":"/doc/ros2/Releases/Release-Bouncy-Bolson/","title":"ROS 2 Bouncy Bolson (codename ‘bouncy’; June 2018)","content":"\nROS 2 Bouncy Bolson (codename ‘bouncy’; June 2018)¶\n\nTable of Contents\n\nSupported Platforms\nFeatures\nNew features in this ROS 2 release\nChanges since the Ardent release\n\n\nKnown Issues\n\n\nBouncy Bolson is the second release of ROS 2.\n\nSupported Platforms¶\nThis version of ROS 2 is supported on four platforms (see REP 2000 for full details):\n\nUbuntu 18.04 (Bionic)\nDebian packages for amd64 as well as arm64\n\n\nUbuntu 16.04 (Xenial)\nno Debian packages but building from source is supported\n\n\nMac OS X 10.12 (Sierra)\nWindows 10 with Visual Studio 2017\n\nBinary packages as well as instructions for how to compile from source are provided (see install instructions as well as documentation).\n\n\nFeatures¶\n\nNew features in this ROS 2 release¶\n\nNew launch system featuring a much more capable and flexible Python API.\nParameters can be passed as command line arguments to C++ executables.\nStatic remapping via command line arguments.\nVarious improvements to the Python client library.\nSupport for publishing and subscribing to serialized data.\nThis is the foundation for the upcoming work towards a native rosbag implementation.\nMore command line tools, e.g. for working with parameters and lifecycle states.\nBinary packages / fat archives support three RMW implementations by default (without the need to build from source):\neProsima’s FastRTPS (default)\nRTI’s Connext\nADLINK’s OpenSplice\n\n\n\nFor an overview of all features available, including those from earlier releases, please see the Features page.\n\n\nChanges since the Ardent release¶\nChanges since the Ardent Apalone release:\n\nThe Python package launch has been redesigned.\nThe previous Python API has been moved into a submodule launch.legacy.\nYou can update existing launch files to continue to use the legacy API if a transition to the new Python API is not desired.\nThe ROS topic names containing namespaces are mapped to DDS topics including their namespaces.\nDDS partitions are not being used anymore for this.\nThe recommended build tool is now colcon instead of ament_tools.\nThis switch has no implications for the code in each ROS 2 package.\nThe install instructions have been updated and the read-the-docs page describes how to map an existing ament_tools call to colcon.\nThe argument order of this rclcpp::Node::create_subscription() signature has been modified.\n\n\n\n\nKnown Issues¶\n\nNew-style launch files may hang on shutdown for some combinations of platform and RMW implementation.\nStatic remapping of namespaces not working correctly when addressed to a particular node.\nOpensplice error messages may be printed when using ros2 param and ros2 lifecycle command-line tools.\n\n\n\n"},{"id":39,"url":"/doc/ros2/Tutorials/Real-Time-Programming/","title":"Real-Time Programming in ROS 2","content":"\nReal-Time Programming in ROS 2¶\n\nTable of Contents\n\nBackground\nInstall and run the demo\nRun the tests\nWhat the heck just happened?\nAdjust permissions for memory locking\nOutput overview\nLatency\nSetting permissions for the scheduler\nPlotting results\n\n\n\n\n\nBackground¶\nReal-time computing is a key feature of many robotics systems, particularly safety- and mission-critical applications such as autonomous vehicles, spacecrafts, and industrial manufacturing.\nWe are designing and prototyping ROS 2 with real-time performance constraints in mind, since this is a requirement that was not considered in the early stages of ROS 1 and it is now intractable to refactor ROS 1 to be real-time friendly.\nThis document outlines the requirements of real-time computing and best practices for software engineers. tl;dr:\nTo make a real-time computer system, our real-time loop must update periodically to meet deadlines.\nWe can only tolerate a small margin of error on these deadlines (our maximum allowable jitter).\nTo do this, we must avoid nondeterministic operations in the execution path, things like: pagefault events, dynamic memory allocation/deallocation, and synchronization primitives that block indefinitely.\nA classic example of a controls problem commonly solved by real-time computing is balancing an inverted pendulum.\nIf the controller blocked for an unexpectedly long amount of time, the pendulum would fall down or go unstable.\nBut if the controller reliably updates at a rate faster than the motor controlling the pendulum can operate, the pendulum will successfully adapt react to sensor data to balance the pendulum.\nNow that you know everything about real-time computing, let’s try a demo!\n\n\nInstall and run the demo¶\nThe real-time demo was written with Linux operating systems in mind, since many members of the ROS community doing real-time computing use Xenomai or RT_PREEMPT as their real-time solutions.\nSince many of the operations done in the demo to optimize performance or OS-specific, the demo only builds and runs on Linux systems.\nSo, if you are an OSX or Windows user, don’t try this part!\nAlso this must be built from source using a the static DDS API. Currently the only supported implementation is Connext.\nFirst, follow the instructions to build ROS 2 from source using Connext DDS as the middleware.\n\nRun the tests¶\nBefore you run make sure you have at least 8Gb of RAM free. With the memory locking, swap will not work anymore.\nSource your ROS 2 setup.bash.\nRun the demo binary, and redirect the output. You may want to use sudo in case you get permission error:\npendulum_demo > output.txt\n\n\n\n\nWhat the heck just happened?¶\nFirst, even though you redirected stdout, you will see some output to the console (from stderr):\nmlockall failed: Cannot allocate memory\nCouldn't lock all cached virtual memory.\nPagefaults from reading pages not yet mapped into RAM will be recorded.\n\n\nAfter the initialization stage of the demo program, it will attempt to lock all cached memory into RAM and prevent future dynamic memory allocations using mlockall.\nThis is to prevent pagefaults from loading lots of new memory into RAM.\n(See the realtime design article for more information.)\nThe demo will continue on as usual when this occurs.\nAt the bottom of the output.txt file generated by the demo, you’ll see the number of pagefaults encountered during execution:\nrttest statistics:\n  - Minor pagefaults: 20\n  - Major pagefaults: 0\n\n\nIf we want those pagefaults to go away, we’ll have to...\n\n\nAdjust permissions for memory locking¶\nAdd to /etc/security/limits.conf (as sudo):\n<your username>    -   memlock   <limit in kB>\n\n\nA limit of -1 is unlimited.\nIf you choose this, you may need to accompany it with ulimit -l unlimited after editing the file.\nAfter saving the file, log out and log back in.\nThen rerun the pendulum_demo invocation.\nYou’ll either see zero pagefaults in your output file, or an error saying that a bad_alloc exception was caught.\nIf this happened, you didn’t have enough free memory available to lock the memory allocated for the process into RAM.\nYou’ll need to install more RAM in your computer to see zero pagefaults!\n\n\nOutput overview¶\nTo see more output, we have to run the pendulum_logger node.\nIn one shell with your install/setup.bash sourced, invoke:\npendulum_logger\n\n\nYou should see the output message:\nLogger node initialized.\n\n\nIn another shell with setup.bash sourced, invoke pendulum_demo again.\nAs soon as this executable starts, you should see the other shell constantly printing output:\nCommanded motor angle: 1.570796\nActual motor angle: 1.570796\nMean latency: 210144.000000 ns\nMin latency: 4805 ns\nMax latency: 578137 ns\nMinor pagefaults during execution: 0\nMajor pagefaults during execution: 0\n\n\nThe demo is controlling a very simple inverted pendulum simulation.\nThe pendulum simulation calculates its position in its own thread.\nA ROS node simulates a motor encoder sensor for the pendulum and publishes its position.\nAnother ROS node acts as a simple PID controller and calculates the next command message.\nThe logger node periodically prints out the pendulum’s state and the runtime performance statistics of the demo during its execution phase.\nAfter the pendulum_demo is finished, you’ll have to CTRL-C out of the logger node to exit.\n\n\nLatency¶\nAt the pendulum_demo execution, you’ll see the final statistics collected for the demo:\nrttest statistics:\n  - Minor pagefaults: 0\n  - Major pagefaults: 0\n  Latency (time after deadline was missed):\n    - Min: 3354 ns\n    - Max: 2752187 ns\n    - Mean: 19871.8 ns\n    - Standard deviation: 1.35819e+08\n\nPendulumMotor received 985 messages\nPendulumController received 987 messages\n\n\nThe latency fields show you the minimum, maximum, and average latency of the update loop in nanoseconds.\nHere, latency means the amount of time after the update was expected to occur.\nThe requirements of a real-time system depend on the application, but let’s say in this demo we have a 1KHz (1 millisecond) update loop, and we’re aiming for a maximum allowable latency of 5% of our update period.\nSo, our average latency was really good in this run, but the maximum latency was unacceptable because it actually exceeded our update loop! What happened?\nWe may be suffering from a non-deterministic scheduler.\nIf you’re running a vanilla Linux system and you don’t have the RT_PREEMPT kernel installed, you probably won’t be able to meet the real-time goal we set for ourselves, because the Linux scheduler won’t allow you to arbitrarily pre-empt threads at the user level.\nSee the realtime design article for more information.\nThe demo attempts to set the scheduler and thread priority of the demo to be suitable for real-time performance.\nIf this operation failed, you’ll see an error message: “Couldn’t set scheduling priority and policy: Operation not permitted”.\nYou can get slightly better performance by following the instructions in the next section:\n\n\nSetting permissions for the scheduler¶\nAdd to /etc/security/limits.conf (as sudo):\n<your username>    -   rtprio   98\n\n\nThe range of the rtprio (real-time priority) field is 0-99.\nHowever, do NOT set the limit to 99 because then your processes could interfere with important system processes that run at the top priority (e.g. watchdog).\nThis demo will attempt to run the control loop at priority 98.\n\n\nPlotting results¶\nYou can plot the latency and pagefault statistics that are collected in this demo after the demo runs.\nBecause the code has been instrumented with rttest, there are useful command line tools available to us:\n-i Specify how many iterations to run the real-time loop.\nDefault is 1000.\n-u Specify the update period.\nDefault units are microseconds.\nUse the suffix “s” for seconds, “ms” for milliseconds, “us” for microseconds, and “ns” for nanoseconds.\nDefault update period is 1ms.\n-f Specify the name of the file for writing the collected data.\nRun the demo again with the name a file to save results to:\npendulum_demo -f pendulum_demo_results\n\n\nThen run the rttest_plot script on the resulting file:\nrttest_plot pendulum_demo_results\n\n\nThis script will produce three files:\npendulum_demo_results_plot_latency.svg\npendulum_demo_results_plot_majflts.svg\npendulum_demo_results_plot_minflts.svg\n\n\nYou can view these plots in an image viewer of your choice.\n\n\n\n"}]
[{"id":56,"url":"/doc/ros2/Installation/Linux-Development-Setup/","title":"Building ROS 2 on Linux","content":"\nBuilding ROS 2 on Linux¶\n\nTable of Contents\n\nSystem Requirements\nSystem setup\nAdd the ROS 2 apt repository\nInstall development tools and ROS tools\n\n\nGet ROS 2.0 code\nInstall dependencies using rosdep\nInstall more DDS implementations (Optional)\nPrismTech OpenSplice Debian Packages built by OSRF\nRTI Connext (version 5.3.1)\n\n\nBuild the code in the workspace\nTry some examples\nAlternate compilers\nClang\n\n\nTroubleshooting\nInternal compiler error\nOut of memory\nMultiple Host Interference\n\n\n\n\n\nSystem Requirements¶\nTarget platforms for Bouncy Bolson (see REP 2000).\n- Ubuntu Linux Xenial Xerus 16.04 64-bit\n- Ubuntu Linux Bionic Beaver 18.04 64-bit\nRecommended Support (not actively tested or supported)\n- Debian Stretch\n- Fedora 26, see alternate instructions.\n- Arch Linux, see alternate instructions.\nMake sure that you have a locale set which supports UTF-8 We test with the following settings.\nIf you are in a minimal environment such as a docker containers the locale may be set to something minimal like POSIX.\nTo set the locale an example is below. It should be fine if you’re using a different UTF-8 supported locale.\nsudo locale-gen en_US en_US.UTF-8\nsudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8\nexport LANG=en_US.UTF-8\n\n\n\n\nSystem setup¶\n\nAdd the ROS 2 apt repository¶\nFirst make sure you have the ROS 2 apt repositories added to your system, if not refer to the following section.\n\n\nInstall development tools and ROS tools¶\nsudo apt update && sudo apt install -y \\\n  build-essential \\\n  cmake \\\n  git \\\n  python3-colcon-common-extensions \\\n  python3-pip \\\n  python-rosdep \\\n  python3-vcstool \\\n  wget\n# install some pip packages needed for testing\nsudo -H python3 -m pip install -U \\\n  argcomplete \\\n  flake8 \\\n  flake8-blind-except \\\n  flake8-builtins \\\n  flake8-class-newline \\\n  flake8-comprehensions \\\n  flake8-deprecated \\\n  flake8-docstrings \\\n  flake8-import-order \\\n  flake8-quotes \\\n  git+https://github.com/lark-parser/lark.git@0.7b \\\n  pytest-repeat \\\n  pytest-rerunfailures \\\n  pytest \\\n  pytest-cov \\\n  pytest-runner \\\n  setuptools\n# install Fast-RTPS dependencies\nsudo apt install --no-install-recommends -y \\\n  libasio-dev \\\n  libtinyxml2-dev\n\n\n\n\n\nGet ROS 2.0 code¶\nCreate a workspace and clone all repos:\nmkdir -p ~/ros2_ws/src\ncd ~/ros2_ws\nwget https://raw.githubusercontent.com/ros2/ros2/release-latest/ros2.repos\nvcs import src < ros2.repos\n\n\n\nNote: if you want to get all of the latest bug fixes then you can try the “tip” of development by replacing release-latest in the URL above with master. The release-latest is preferred by default because it goes through more rigorous testing on release than changes to master do. See also Maintaining a Source Checkout.\n\n\nInstall dependencies using rosdep¶\nsudo rosdep init\nrosdep update\n# [Ubuntu 18.04]\nrosdep install --from-paths src --ignore-src --rosdistro crystal -y --skip-keys \"console_bridge fastcdr fastrtps libopensplice67 libopensplice69 rti-connext-dds-5.3.1 urdfdom_headers\"\n# [Ubuntu 16.04]\nrosdep install --from-paths src --ignore-src --rosdistro crystal -y --skip-keys \"console_bridge fastcdr fastrtps libopensplice67 libopensplice69 python3-lark-parser rti-connext-dds-5.3.1 urdfdom_headers\"\n\n\n\n\nInstall more DDS implementations (Optional)¶\nROS 2.0 builds on top of DDS.\nIt is compatible with multiple DDS or RTPS (the DDS wire protocol) vendors.\nThe repositories you downloaded for ROS 2.0 includes eProsima’s Fast RTPS, which is the only bundled vendor.\nIf you would like to use one of the other vendors you will need to install their software separately before building.\nThe ROS 2.0 build will automatically build support for vendors that have been installed and sourced correctly.\nBy default we include eProsima’s FastRTPS in the workspace and it is the default middleware. Detailed instructions for installing other DDS vendors are provided below.\n\nPrismTech OpenSplice Debian Packages built by OSRF¶\n# For Crystal Clemmys\nsudo apt install libopensplice69  # from packages.ros.org/ros2/ubuntu\n\n# For Bouncy Bolson\nsudo apt install libopensplice67  # from packages.ros.org/ros2/ubuntu\n\n\nAdd this to your ~/.bashrc\nexport OSPL_URI=file:///usr/etc/opensplice/config/ospl.xml\n\n\n\n\nRTI Connext (version 5.3.1)¶\n\nDebian packages provided in the ROS 2 apt repositories¶\nYou can install a Debian package of RTI Connext available on the ROS 2 apt repositories.\nYou will need to accept a license from RTI.\nsudo apt install -q -y \\\n    rti-connext-dds-5.3.1  # from packages.ros.org/ros2/ubuntu\n\n\nSource the setup file to set the NDDSHOME environment variable.\ncd /opt/rti.com/rti_connext_dds-5.3.1/resource/scripts && source ./rtisetenv_x64Linux3gcc5.4.0.bash; cd -\n\n\nNote: when using zsh you need to be in the directory of the script when sourcing it to have it work properly\nNow you can build as normal and support for RTI will be built as well.\nIf you want to install the Connext DDS-Security plugins please refer to this page\n\n\nOfficial binary packages from RTI¶\nYou can install the Connext 5.3.1 package for Linux provided by RTI from their downloads page.\nTo use RTI Connext you will need to have obtained a license from RTI.\nAdd the following line to your .bashrc file pointing to your copy of the license.\nexport RTI_LICENSE_FILE=path/to/rti_license.dat\n\n\nAfter downloading, use chmod +x on the .run executable and then execute it.\nNote that if you’re installing to a system directory use sudo as well.\nThe default location is ~/rti_connext_dds-5.3.1\nSource the setup file to set the NDDSHOME environment variable.\nsource ~/rti_connext_dds-5.3.1/resource/scripts/rtisetenv_x64Linux3gcc5.4.0.bash\n\n\nNow you can build as normal and support for RTI will be built as well.\n\n\n\n\nBuild the code in the workspace¶\nNote: to build the ROS 1 bridge, read the ros1_bridge instructions.\nMore info on working with a ROS workspace can be found in this tutorial.\ncd ~/ros2_ws/\n# On Ubuntu Linux Bionic Beaver 18.04\ncolcon build --symlink-install\n# On Ubuntu Linux Xenial Xerus 16.04\ncolcon build --symlink-install --packages-ignore qt_gui_cpp rqt_gui_cpp\n\n\nNote: if you are having trouble compiling all examples and this is preventing you from completing a successful build, you can use AMENT_IGNORE in the same manner as CATKIN_IGNORE to ignore the subtree or remove the folder from the workspace.\nTake for instance: you would like to avoid installing the large OpenCV library.\nWell then simply $ touch AMENT_IGNORE in the cam2image demo directory to leave it out of the build process.\nOptionally install all packages into a combined directory (rather than each package in a separate subdirectory).\nOn Windows due to limitations of the length of environment variables you should use this option when building workspaces with many (~ >> 100 packages).\nAlso, if you have already installed ROS2 from Debian make sure that you run the build command in a fresh environment. You may want to make sure that you do not have source /opt/ros/${ROS_DISTRO}/setup.bash in your .bashrc.\ncolcon build --symlink-install --merge-install\n\n\nAfterwards source the local_setup.* from the install folder.\n\n\nTry some examples¶\nIn one terminal, source the setup file and then run a talker:\n. ~/ros2_ws/install/local_setup.bash\nros2 run demo_nodes_cpp talker\n\n\nIn another terminal source the setup file and then run a listener:\n. ~/ros2_ws/install/local_setup.bash\nros2 run demo_nodes_py listener\n\n\nYou should see the talker saying that it’s Publishing messages and the listener saying I heard those messages.\nHooray!\nSee the demos for other things to try.\n\n\nAlternate compilers¶\nUsing a different compiler besides gcc to compile ROS 2 is easy. If you set the environment variables CC and CXX to executables for a working C and C++ compiler, respectively, and retrigger CMake configuration (by using --force-cmake-config or by deleting the packages you want to be affected), CMake will reconfigure and use the different compiler.\n\nClang¶\nTo configure CMake to detect and use Clang:\nsudo apt install clang\nexport CC=clang\nexport CXX=clang++\ncolcon build --cmake-force-configure\n\n\nTODO: using ThreadSanitizer, MemorySanitizer\n\n\n\nTroubleshooting¶\n\nInternal compiler error¶\nIf you experience an ICE when trying to compile on a memory constrained platform like a Raspberry PI you might want to build single threaded (prefix the build invocation with MAKEFLAGS=-j1).\n\n\nOut of memory¶\nThe ros1_bridge in its current form requires 4Gb of free RAM to compile.\nIf you don’t have that amount of RAM available it’s suggested to use AMENT_IGNORE in that folder and skip its compilation.\n\n\nMultiple Host Interference¶\nIf you’re running multiple instances on the same network you may get interference.\nTo avoid this you can set the environment variable ROS_DOMAIN_ID to a different integer, the default is zero.\nThis will define the DDS domain id for your system.\nNote that if you are using the OpenSplice DDS implementation you will also need to update the OpenSplice configuration file accordingly. The location of the configuration file is referenced in the OSPL_URI environment variable.\n\n\n\n"},{"id":57,"url":"/doc/ros2/Related-Projects/Intel-ROS2-Projects/","title":"Intel ROS2 Projects","content":"\nIntel ROS2 Projects¶\nIntel® Robotics Open Source Project (Intel® ROS Project) to enable object detection/location/tracking, people detection, vehicle detection, industry robot arm grasp point analysis with kinds of Intel technologies and platforms, including CPU, GPU, Intel® Movidius™ NCS optimized deep learning backend, FPGA, Intel® RealSense™ camera, etc.\n\nKey Projects¶\nWe are working on below ROS2 projects and publish source code through https://github.com/intel/ or ROS2 github repo gradually.\n\nROS2 OpenVINO: ROS2 package for Intel® Visual Inference and Neural Network Optimization Toolkit to develop multiplatform computer vision solutions.\nROS2 RealSense Camera: ROS2 package for Intel® RealSense™ D400 serial cameras\nROS2 Movidius NCS: ROS2 package for object detection with Intel® Movidius™ Neural Computing Stick (NCS).\nROS2 Object Messages: ROS2 messages for object.\nROS2 Object Analytics: ROS2 package for object detection, tracking and 2D/3D localization.\nROS2 Message Filters: ROS2 package for message synchronization with time stamp.\nROS2 CV Bridge: ROS2 package to bridge with openCV.\nROS2 Object Map: ROS2 package to mark tag of objects on map when SLAM based on information provided by ROS2 object analytics.\nROS2 Moving Object: ROS2 package to provide object motion information (like object velocity on x, y, z axis) based on information provided by ROS2 object analytics.\nROS2 Grasp Library: Coming soon. ROS2 package for grasp position analysis, and compatible with MoveIt grasp interfaces.\n\n\n\nReference¶\nROS components at: http://wiki.ros.org/IntelROSProject shows the relationship among those packages, which also applies to ROS2.\n\n\n"},{"id":58,"url":"/doc/ros2/Tutorials/Allocator-Template-Tutorial/","title":"Implement a custom memory allocator","content":"\nImplement a custom memory allocator¶\n\nTable of Contents\n\nBackground\nWriting an allocator\nWriting an example main\nPassing an allocator to the intra-process pipeline\nTesting and verifying the code\nThe TLSF allocator\n\n\nThis tutorial will teach you how to integrate a custom allocator for publishers and subscribers so that the default heap allocator is never called while your ROS nodes are executing.\nThe code for this tutorial is available here.\n\nBackground¶\nSuppose you want to write real-time safe code, and you’ve heard about the many dangers of calling “new” during the real-time critical section, because the default heap allocator on most platforms is nondeterministic.\nBy default, many C++ standard library structures will implicitly allocate memory as they grow, such as std::vector. However, these data structures also accept an “Allocator” template argument. If you specify a custom allocator to one of these data structures, it will use that allocator for you instead of the system allocator to grow or shrink the data structure. Your custom allocator could have a pool of memory preallocated on the stack, which might be better suited to real-time applications.\nIn the ROS 2 C++ client library (rclcpp), we are following a similar philosophy to the C++ standard library. Publishers, subscribers, and the Executor accept an Allocator template parameter that controls allocations made by that entity during execution.\n\n\nWriting an allocator¶\nTo write an allocator compatible with ROS 2’s allocator interface, your allocator must be compatible with the C++ standard library allocator interface.\nThe C++11 library provides something called allocator_traits. The C++11 standard specifies that a custom allocator only needs to fulfil a minimal set of requirements to be used to allocate and deallocate memory in a standard way. allocator_traits is a generic structure that fills out other qualities of an allocator based on an allocator written with the minimal requirements.\nFor example, the following declaration for a custom allocator would satisfy allocator_traits (of course, you would still need to implement the declared functions in this struct):\ntemplate <class T>\nstruct custom_allocator {\n  using value_type = T;\n  custom_allocator() noexcept;\n  template <class U> custom_allocator (const custom_allocator<U>&) noexcept;\n  T* allocate (std::size_t n);\n  void deallocate (T* p, std::size_t n);\n};\n\ntemplate <class T, class U>\nconstexpr bool operator== (const custom_allocator<T>&, const custom_allocator<U>&) noexcept;\n\ntemplate <class T, class U>\nconstexpr bool operator!= (const custom_allocator<T>&, const custom_allocator<U>&) noexcept;\n\n\nYou could then access other functions and members of the allocator filled in by allocator_traits like so: std::allocator_traits<custom_allocator<T>>::construct(...)\nTo learn about the full capabilities of allocator_traits, see http://en.cppreference.com/w/cpp/memory/allocator_traits .\nHowever, some compilers that only have partial C++11 support, such as GCC 4.8, still require allocators to implement a lot of boilerplate code to work with standard library structures such as vectors and strings, because these structures do not use allocator_traits internally. Therefore, if you’re using a compiler with partial C++11 support, your allocator will need to look more like this:\ntemplate<typename T>\nstruct pointer_traits {\n  using reference = T &;\n  using const_reference = const T &;\n};\n\n// Avoid declaring a reference to void with an empty specialization\ntemplate<>\nstruct pointer_traits<void> {\n};\n\ntemplate<typename T = void>\nstruct MyAllocator : public pointer_traits<T> {\npublic:\n  using value_type = T;\n  using size_type = std::size_t;\n  using pointer = T *;\n  using const_pointer = const T *;\n  using difference_type = typename std::pointer_traits<pointer>::difference_type;\n\n  MyAllocator() noexcept;\n\n  ~MyAllocator() noexcept;\n\n  template<typename U>\n  MyAllocator(const MyAllocator<U> &) noexcept;\n\n  T * allocate(size_t size, const void * = 0);\n\n  void deallocate(T * ptr, size_t size);\n\n  template<typename U>\n  struct rebind {\n    typedef MyAllocator<U> other;\n  };\n};\n\ntemplate<typename T, typename U>\nconstexpr bool operator==(const MyAllocator<T> &,\n  const MyAllocator<U> &) noexcept;\n\ntemplate<typename T, typename U>\nconstexpr bool operator!=(const MyAllocator<T> &,\n  const MyAllocator<U> &) noexcept;\n\n\n\n\nWriting an example main¶\nOnce you have written a valid C++ allocator, you must pass it as a shared pointer to your publisher, subscriber, and executor.\nauto alloc = std::make_shared<MyAllocator<void>>();\nauto publisher = node->create_publisher<std_msgs::msg::UInt32>(\"allocator_example\", 10, alloc);\nauto msg_mem_strat =\n  std::make_shared<rclcpp::message_memory_strategy::MessageMemoryStrategy<std_msgs::msg::UInt32,\n  MyAllocator<>>>(alloc);\nauto subscriber = node->create_subscription<std_msgs::msg::UInt32>(\n  \"allocator_example\", 10, callback, nullptr, false, msg_mem_strat, alloc);\n\nstd::shared_ptr<rclcpp::memory_strategy::MemoryStrategy> memory_strategy =\n  std::make_shared<AllocatorMemoryStrategy<MyAllocator<>>>(alloc);\nrclcpp::executors::SingleThreadedExecutor executor(memory_strategy);\n\n\nYou will also need to use your allocator to allocate any messages that you pass along the execution codepath.\nauto alloc = std::make_shared<MyAllocator<void>>();\n\n\nOnce you’ve instantiated the node and added the executor to the node, it’s time to spin:\nuint32_t i = 0;\nwhile (rclcpp::ok()) {\n  msg->data = i;\n  i++;\n  publisher->publish(msg);\n  rclcpp::utilities::sleep_for(std::chrono::milliseconds(1));\n  executor.spin_some();\n}\n\n\n\n\nPassing an allocator to the intra-process pipeline¶\nEven though we instantiated a publisher and subscriber in the same process, we aren’t using the intra-process pipeline yet.\nThe IntraProcessManager is a class that is usually hidden from the user, but in order to pass a custom allocator to it we need to expose it by getting it from the rclcpp Context. The IntraProcessManager makes use of several standard library structures, so without a custom allocator it will call the default new.\nauto context = rclcpp::contexts::default_context::get_global_default_context();\nauto ipm_state =\n  std::make_shared<rclcpp::intra_process_manager::IntraProcessManagerState<MyAllocator<>>>();\n// Constructs the intra-process manager with a custom allocator.\ncontext->get_sub_context<rclcpp::intra_process_manager::IntraProcessManager>(ipm_state);\nauto node = rclcpp::Node::make_shared(\"allocator_example\", true);\n\n\nMake sure to instantiate publishers and subscribers AFTER constructing the node in this way.\n\n\nTesting and verifying the code¶\nHow do you know that your custom allocator is actually getting called?\nThe obvious thing to do would be to count the calls made to your custom allocator’s allocate and deallocate functions and compare that to the calls to new and delete.\nAdding counting to the custom allocator is easy:\nT * allocate(size_t size, const void * = 0) {\n  // ...\n  num_allocs++;\n  // ...\n}\n\nvoid deallocate(T * ptr, size_t size) {\n  // ...\n  num_deallocs++;\n  // ...\n}\n\n\nYou can also override the global new and delete operators:\nvoid operator delete(void * ptr) noexcept {\n  if (ptr != nullptr) {\n    if (is_running) {\n      global_runtime_deallocs++;\n    }\n    std::free(ptr);\n    ptr = nullptr;\n  }\n}\n\nvoid operator delete(void * ptr, size_t) noexcept {\n  if (ptr != nullptr) {\n    if (is_running) {\n      global_runtime_deallocs++;\n    }\n    std::free(ptr);\n    ptr = nullptr;\n  }\n}\n\n\nwhere the variables we are incrementing are just global static integers, and is_running is a global static boolean that gets toggled right before the call to spin.\nThe example executable prints the value of the variables. To run the example executable, use:\nallocator_example\n\n\nor, to run the example with the intra-process pipeline on:\nallocator_example intra-process\n\n\nYou should get numbers like:\nGlobal new was called 15590 times during spin\nGlobal delete was called 15590 times during spin\nAllocator new was called 27284 times during spin\nAllocator delete was called 27281 times during spin\n\n\nWe’ve caught about 2/3 of the allocations/deallocations that happen on the execution path, but where do the remaining 1/3 come from?\nAs a matter of fact, these allocations/deallocations originate in the underlying DDS implementation used in this example.\nProving this is out of the scope of this tutorial, but you can check out the test for the allocation path that gets run as part of the ROS 2 continuous integration testing, which backtraces through the code and figures out whether certain function calls originate in the rmw implementation or in a DDS implementation:\nhttps://github.com/ros2/realtime_support/blob/master/tlsf_cpp/test/test_tlsf.cpp#L41\nNote that this test is not using the custom allocator we just created, but the TLSF allocator (see below).\n\n\nThe TLSF allocator¶\nROS 2 offers support for the TLSF (Two Level Segregate Fit) allocator, which was designed to meet real-time requirements:\nhttps://github.com/ros2/realtime_support/tree/master/tlsf_cpp\nFor more information about TLSF, see http://www.gii.upv.es/tlsf/\nNote that the TLSF allocator is licensed under a dual-GPL/LGPL license.\nA full working example using the TLSF allocator is here:\nhttps://github.com/ros2/realtime_support/blob/master/tlsf_cpp/example/allocator_example.cpp\n\n\n"},{"id":59,"url":"/doc/ros2/Tutorials/Intra-Process-Communication/","title":"Efficient intra-process communication","content":"\nEfficient intra-process communication¶\n\nTable of Contents\n\nBackground\nBuild the demos\nRunning and understanding the demos\nLooking forward\n\n\n\nBackground¶\nROS applications typically consist of a composition of individual “nodes” which perform narrow tasks and are decoupled from other parts of the system.\nThis promotes fault isolation, faster development, modularity, and code reuse, but it often comes at the cost of performance.\nAfter ROS 1 was initially developed, the need for efficient composition of nodes became obvious and Nodelets were developed.\nIn ROS 2 we aim to improve on the design of Nodelets by addressing some fundamental problems that required restructuring of nodes.\nIn this demo we’ll be highlighting how nodes can be composed manually, by defining the nodes separately but combining them in different process layouts without changing the node’s code or limiting its abilities.\n\n\nBuild the demos¶\nThese demos should work on any of the three major OSs (Windows, Mac, or Linux).\nSome of them do require OpenCV to have been installed.\n\nUsing the pre-built binaries¶\nIf you’ve installed the binaries, simply source the ROS 2 setup file and then skip down to any of the individual demos to see how to run them.\n\n\nBuilding from source¶\nMake sure you have OpenCV installed and then follow the source instructions.\nYou can find the from source instructions linked from the main ros2 installation page.\nOnce built source the setup file and continue down to one of the specific demos to read about them and for instructions on how to run them.\n\n\n\nRunning and understanding the demos¶\nThere are a few different demos: some are toy problems designed to highlight features of the intra process communications functionality and some are end to end examples which use OpenCV and demonstrate the ability to recombine nodes into different configurations.\n\nThe two node pipeline demo¶\nThis demo is designed to show that the intra process publish/subscribe connection can result in zero-copy transport of messages when publishing and subscribing with std::unique_ptrs.\nFirst let’s take a look at the source:\nhttps://github.com/ros2/demos/blob/master/intra_process_demo/src/two_node_pipeline/two_node_pipeline.cpp\n#include <chrono>\n#include <cinttypes>\n#include <cstdio>\n#include <memory>\n#include <string>\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/int32.hpp\"\n\nusing namespace std::chrono_literals;\n\n// Node that produces messages.\nstruct Producer : public rclcpp::Node\n{\n  Producer(const std::string & name, const std::string & output)\n  : Node(name, \"\", true)\n  {\n    // Create a publisher on the output topic.\n    pub_ = this->create_publisher<std_msgs::msg::Int32>(output, rmw_qos_profile_default);\n    std::weak_ptr<std::remove_pointer<decltype(pub_.get())>::type> captured_pub = pub_;\n    // Create a timer which publishes on the output topic at ~1Hz.\n    auto callback = [captured_pub]() -> void {\n        auto pub_ptr = captured_pub.lock();\n        if (!pub_ptr) {\n          return;\n        }\n        static int32_t count = 0;\n        std_msgs::msg::Int32::UniquePtr msg(new std_msgs::msg::Int32());\n        msg->data = count++;\n        printf(\n          \"Published message with value: %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n          reinterpret_cast<std::uintptr_t>(msg.get()));\n        pub_ptr->publish(msg);\n      };\n    timer_ = this->create_wall_timer(1s, callback);\n  }\n\n  rclcpp::Publisher<std_msgs::msg::Int32>::SharedPtr pub_;\n  rclcpp::TimerBase::SharedPtr timer_;\n};\n\n// Node that consumes messages.\nstruct Consumer : public rclcpp::Node\n{\n  Consumer(const std::string & name, const std::string & input)\n  : Node(name, \"\", true)\n  {\n    // Create a subscription on the input topic which prints on receipt of new messages.\n    sub_ = this->create_subscription<std_msgs::msg::Int32>(\n      input, [](std_msgs::msg::Int32::UniquePtr msg) {\n      printf(\n        \" Received message with value: %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n        reinterpret_cast<std::uintptr_t>(msg.get()));\n    }, rmw_qos_profile_default);\n  }\n\n  rclcpp::Subscription<std_msgs::msg::Int32>::SharedPtr sub_;\n};\n\nint main(int argc, char * argv[])\n{\n  setvbuf(stdout, NULL, _IONBF, BUFSIZ);\n  rclcpp::init(argc, argv);\n  rclcpp::executors::SingleThreadedExecutor executor;\n\n  auto producer = std::make_shared<Producer>(\"producer\", \"number\");\n  auto consumer = std::make_shared<Consumer>(\"consumer\", \"number\");\n\n  executor.add_node(producer);\n  executor.add_node(consumer);\n  executor.spin();\n  return 0;\n}\n\n\nAs you can see by looking at the main function, we have a producer and a consumer node, we add them to a single threaded executor, and then call spin.\nIf you look at the “producer” node’s implementation in the Producer struct, you can see that we have created a publisher which publishes on the “number” topic and a timer which periodically creates a new message, prints out its address in memory and its content’s value and then publishes it.\nThe “consumer” node is a bit simpler, you can see its implementation in the Consumer struct, as it only subscribes to the “number” topic and prints the address and value of the message it receives.\nThe expectation is that the producer will print out an address and value and the consumer will print out a matching address and value.\nThis demonstrates that intra process communication is indeed working and unnecessary copies are avoided, at least for simple graphs.\nLet’s run the demo by executing ros2 run intra_process_demo two_node_pipeline executable (don’t forget to source the setup file first):\n$ ros2 run intra_process_demo two_node_pipeline\nPublished message with value: 0, and address: 0x7fb02303faf0\nPublished message with value: 1, and address: 0x7fb020cf0520\n Received message with value: 1, and address: 0x7fb020cf0520\nPublished message with value: 2, and address: 0x7fb020e12900\n Received message with value: 2, and address: 0x7fb020e12900\nPublished message with value: 3, and address: 0x7fb020cf0520\n Received message with value: 3, and address: 0x7fb020cf0520\nPublished message with value: 4, and address: 0x7fb020e12900\n Received message with value: 4, and address: 0x7fb020e12900\nPublished message with value: 5, and address: 0x7fb02303cea0\n Received message with value: 5, and address: 0x7fb02303cea0\n[...]\n\n\nOne thing you’ll notice is that the messages tick along at about one per second.\nThis is because we told the timer to fire at about once per second.\nAlso you may have noticed that the first message (with value 0) does not have a corresponding “Received message ...” line.\nThis is because publish/subscribe is “best effort” and we do not have any “latching” like behavior enabled.\nThis means that if the publisher publishes a message before the subscription has been established, the subscription will not receive that message.\nThis race condition can result in the first few messages being lost.\nIn this case, since they only come once per second, usually only the first message is lost.\nFinally, you can see that “Published message...” and “Received message ...” lines with the same value also have the same address.\nThis shows that the address of the message being received is the same as the one that was published and that it is not a copy.\nThis is because we’re publishing and subscribing with std::unique_ptrs which allow ownership of a message to be moved around the system safely.\nYou can also publish and subscribe with const & and std::shared_ptr, but zero-copy will not occur in that case.\n\n\nThe cyclic pipeline demo¶\nThis demo is similar to the previous one, but instead of the producer creating a new message for each iteration, this demo only ever uses one message instance.\nThis is achieved by creating a cycle in the graph and “kicking off” communication by externally making one of the nodes publish before spinning the executor:\nhttps://github.com/ros2/demos/blob/master/intra_process_demo/src/cyclic_pipeline/cyclic_pipeline.cpp\n#include <chrono>\n#include <cinttypes>\n#include <cstdio>\n#include <memory>\n#include <string>\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/int32.hpp\"\n\nusing namespace std::chrono_literals;\n\n// This node receives an Int32, waits 1 second, then increments and sends it.\nstruct IncrementerPipe : public rclcpp::Node\n{\n  IncrementerPipe(const std::string & name, const std::string & in, const std::string & out)\n  : Node(name, \"\", true)\n  {\n    // Create a publisher on the output topic.\n    pub = this->create_publisher<std_msgs::msg::Int32>(out, rmw_qos_profile_default);\n    std::weak_ptr<std::remove_pointer<decltype(pub.get())>::type> captured_pub = pub;\n    // Create a subscription on the input topic.\n    sub = this->create_subscription<std_msgs::msg::Int32>(\n      in, [captured_pub](std_msgs::msg::Int32::UniquePtr msg) {\n      auto pub_ptr = captured_pub.lock();\n      if (!pub_ptr) {\n        return;\n      }\n      printf(\n        \"Received message with value:         %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n        reinterpret_cast<std::uintptr_t>(msg.get()));\n      printf(\"  sleeping for 1 second...\\n\");\n      if (!rclcpp::sleep_for(1s)) {\n        return;    // Return if the sleep failed (e.g. on ctrl-c).\n      }\n      printf(\"  done.\\n\");\n      msg->data++;    // Increment the message's data.\n      printf(\n        \"Incrementing and sending with value: %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n        reinterpret_cast<std::uintptr_t>(msg.get()));\n      pub_ptr->publish(msg);    // Send the message along to the output topic.\n    }, rmw_qos_profile_default);\n  }\n\n  rclcpp::Publisher<std_msgs::msg::Int32>::SharedPtr pub;\n  rclcpp::Subscription<std_msgs::msg::Int32>::SharedPtr sub;\n};\n\nint main(int argc, char * argv[])\n{\n  setvbuf(stdout, NULL, _IONBF, BUFSIZ);\n  rclcpp::init(argc, argv);\n  rclcpp::executors::SingleThreadedExecutor executor;\n\n  // Create a simple loop by connecting the in and out topics of two IncrementerPipe's.\n  // The expectation is that the address of the message being passed between them never changes.\n  auto pipe1 = std::make_shared<IncrementerPipe>(\"pipe1\", \"topic1\", \"topic2\");\n  auto pipe2 = std::make_shared<IncrementerPipe>(\"pipe2\", \"topic2\", \"topic1\");\n  rclcpp::sleep_for(1s);  // Wait for subscriptions to be established to avoid race conditions.\n  // Publish the first message (kicking off the cycle).\n  std::unique_ptr<std_msgs::msg::Int32> msg(new std_msgs::msg::Int32());\n  msg->data = 42;\n  printf(\n    \"Published first message with value:  %d, and address: 0x%\" PRIXPTR \"\\n\", msg->data,\n    reinterpret_cast<std::uintptr_t>(msg.get()));\n  pipe1->pub->publish(msg);\n\n  executor.add_node(pipe1);\n  executor.add_node(pipe2);\n  executor.spin();\n  return 0;\n}\n\n\nUnlike the previous demo, this demo uses only one Node, instantiated twice with different names and configurations.\nThe graph ends up being pipe1 -> pipe2 -> pipe1 ... in a loop.\nThe line pipe1->pub->publish(msg); kicks the process off, but from then on the messages are passed back and forth between the nodes by each one calling publish within its own subscription callback.\nThe expectation here is that the nodes pass the message back and forth, once a second, incrementing the value of the message each time.\nBecause the message is being published and subscribed to as a unique_ptr the same message created at the beginning is continuously used.\nTo test those expectations, let’s run it:\n% ros2 run intra_process_demo cyclic_pipeline\nPublished first message with value:  42, and address: 0x7fd2ce0a2bc0\nReceived message with value:         42, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 43, and address: 0x7fd2ce0a2bc0\nReceived message with value:         43, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 44, and address: 0x7fd2ce0a2bc0\nReceived message with value:         44, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 45, and address: 0x7fd2ce0a2bc0\nReceived message with value:         45, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 46, and address: 0x7fd2ce0a2bc0\nReceived message with value:         46, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n  done.\nIncrementing and sending with value: 47, and address: 0x7fd2ce0a2bc0\nReceived message with value:         47, and address: 0x7fd2ce0a2bc0\n  sleeping for 1 second...\n[...]\n\n\nYou should see ever increasing numbers on each iteration, starting with 42... because 42, and the whole time it reuses the same message, as demonstrated by the pointer addresses which do not change, which avoids unnecessary copies.\n\n\nThe image pipeline demo¶\nIn this demo we’ll use OpenCV to capture, annotate, and then view images.\nNote for OS X users: If these examples do not work or you receive an error like ddsi_conn_write failed -1 then you’ll need to increase your system wide UDP packet size:\n$ sudo sysctl -w net.inet.udp.recvspace=209715\n$ sudo sysctl -w net.inet.udp.maxdgram=65500\n\n\nThese changes will not persist after a reboot.\n\nSimple pipeline¶\nFirst we’ll have a pipeline of three nodes, arranged as such: camera_node -> watermark_node -> image_view_node\nThe camera_node reads from camera device 0 on your computer, writes some information on the image and publishes it.\nThe watermark_node subscribes to the output of the camera_node and adds more text before publishing it too.\nFinally, the image_view_node subscribes to the output of the watermark_node, writes more text to the image and then visualizes it with cv::imshow.\nIn each node the address of the message which is being sent, or which has been received, or both, is written to the image.\nThe watermark and image view nodes are designed to modify the image without copying it and so the addresses imprinted on the image should all be the same as long as the nodes are in the same process and the graph remains organized in a pipeline as sketched above.\n\nNote\nOn some systems (we’ve seen it happen on Linux), the address printed to the screen might not change.\nThis is because the same unique pointer is being reused. In this situation, the pipeline is still running.\n\nLet’s run the demo by executing the following executable:\nros2 run intra_process_demo image_pipeline_all_in_one\n\n\nYou should see something like this:\n\nYou can pause the rendering of the image by pressing the spacebar and you can resume by pressing the spacebar again.\nYou can also press q or ESC to exit.\nIf you pause the image viewer, you should be able to compare the addresses written on the image and see that they are the same.\n\n\nPipeline with two image viewers¶\nNow let’s look at an example just like the one above, except it has two image view nodes.\nAll the nodes are still in the same process, but now two image view windows should show up. (Note for OS X users: your image view windows might be on top of each other).\nLet’s run it with the command:\nros2 run intra_process_demo image_pipeline_with_two_image_view\n\n\n\nJust like the last example, you can pause the rendering with the spacebar and continue by pressing the spacebar a second time. You can stop the updating to inspect the pointers written to the screen.\nAs you can see in the example image above, we have one image with all of the pointers the same and then another image with the same pointers as the first image for the first two entries, but the last pointer on the second image is different. To understand why this is happening consider the graph’s topology:\ncamera_node -> watermark_node -> image_view_node\n                              -> image_view_node2\n\n\nThe link between the camera_node and the watermark_node can use the same pointer without copying because there is only one intra process subscription to which the message should be delivered. But for the link between the watermark_node and the two image view nodes the relationship is one to many, so if the image view nodes were using unique_ptr callbacks then it would be impossible to deliver the ownership of the same pointer to both. It can be, however, delivered to one of them. Which one would get the original pointer is not defined, but instead is simply the last to be delivered.\nNote that the image view nodes are not subscribed with unique_ptr callbacks. Instead they are subscribed with const shared_ptrs. This means the system could have delivered the same shared_ptr to both callbacks. Currently the intra process system is not that intelligent and so it stores the message internally as a unique_ptr and copies it into a shared_ptr for each callback until the last one. On the last callback, regardless of the type, the ownership is transferred out of intra process storage and, in the case of the image view, the ownership is moved into a new shared_ptr and delivered. Thus, one of the image view nodes gets a copy and the other gets the original.\n\n\nPipeline with interprocess viewer¶\nOne other important thing to get right is to avoid interruption of the intra process zero-copy behavior when interprocess subscriptions are made. To test this we can run the first image pipeline demo, image_pipeline_all_in_one, and then run an instance of the stand alone image_view_node (don’t forget to prefix them with ros2 run intra_process_demo in the terminal). This will look something like this:\n\nIt’s hard to pause both images at the same time so the images may not line up, but the important thing to notice is that the image_pipeline_all_in_one image view shows the same address for each step. This means that the intra process zero-copy is preserved even when an external view is subscribed as well. You can also see that the interprocess image view has different process IDs for the first two lines of text and the process ID of the standalone image viewer in the third line of text.\n\n\n\n\nLooking forward¶\nThese demos are the foundation for some cool new features on which we’re actively working, but right now some things are missing.\n\nRoom for Improvement¶\nLet’s start by looking at what we at OSRF know we can do better or differently and move on from there.\n\nIntra Process Manager Storage¶\nAt the core of the intra process implementation is something called the intra process manager. It is the shared state between nodes (not necessarily global) which facilitates intra process communication. The intra process manager has a lot of room for improvement, but one thing on our short list is to have it be more intelligent about how to store the user’s data internally. In the example with two image view nodes all in the same process, we could have delivered the user’s provided pointer to both image view nodes as copies of a single shared_ptr. This is possible only because of the intra process graph’s structure, but given any relationship of a publisher to one or more intra process subscriptions there should be a preferred solution.\nFor example, imagine if there was a publisher connected to three intra process subscriptions where one was subscribed as a unique_ptr and the other two were subscribed as a shared_ptr. If you store the the message as a unique_ptr then you must make a copy for each of the shared_ptr but you can deliver to the unique_ptr callback without a copy. But if you instead stored the message as a shared_ptr then you give that shared_ptr to the two shared_ptr callbacks and make one copy for the unique_ptr callback, which would save on copies. In both cases we’ve assumed that only one copy of the message should be stored, i.e. we will not store a unique_ptr of the message as well as a shared_ptr copy. There is a performance trade-off when decided whether to make those copies or not, so one thing to figure out moving forward is how and when to expose this trade-off to the developer.\nThis problem gets more interesting when we start doing Type Masquerading :smile:, which we’ll talk about below.\n\n\nAvoiding Unnecessary Interprocess Publishes¶\nCurrently we’re relying on the middleware, the DDS vendor, to avoid publishing to the wire unnecessarily, but no matter what we have to give the middleware a copy of the user’s message. We could avoid this copy given to the system if we could know if it is needed. We can do this currently by checking to see if there are any non intra process subscriptions currently attached to the publisher. The problem with this becomes apparent when we go to implement latching, which we’ll see more about below.\n\n\nAvoiding Memory Allocation¶\nIn other parts of the system we’ve worked really hard to allow users to avoid memory allocation. This has performance benefits and may be required for real-time or embedded scenarios. We cannot currently do that with intra process. Mostly this is because we haven’t had time to figure out the right interfaces, but the general problem is that if a message needs to be delivered to more than one subscription, or if the user gives us a const & or const shared_ptr when publishing, we need to make a copy. And the destination of the copy is currently created using new and is not configurable. We expect to resolve that in the future.\n\n\nPerformance, Performance, Performance¶\nThis is a very rough first draft. There is a lot of room for improvement, even beyond what has been enumerated above. We’ll start to improve performance as we dig into the details of the system, build up a better understanding of exactly what our middleware vendors are doing, and try alternative strategies for implementing intra process.\n\n\n\nWhat’s Missing¶\nAforementioned are some things we can improve with what’s already there. But there are also some things we’d like to add on top of this that are pretty interesting and some things that are just necessary.\n\nLatching¶\nWe haven’t fully implemented the concept of latching yet, but it’s very likely we’ll need to adjust the implementation of the intra process manager to account for the fact that late intra process subscriptions should be delivered to as well. There are several options on how to do that, and we’ll do some testing and figure out what to do in the near future.\n\n\nBeyond Pub/Sub¶\nWe’ve not done any of this with Services, Parameters, or Actions, but we will.\n\n\nType Masquerading¶\nThis is one of the coolest upcoming features that we didn’t get to in this demo.\nImagine the image pipeline demo above, but rather than passing sensor_msgs/Images around, you’re publishing and subscribing to cv::Mat objects. This exists in ROS 1, see: http://wiki.ros.org/roscpp/Overview/MessagesSerializationAndAdaptingTypes\nIn ROS 1, this is accomplished by serializing/deserializing the third party type when handling it. This means that with intra process you’ll be serializing when passing it between nodelets. But in ROS 2 we want to do it in the most performant way possible. Similar to how these demos have been demonstrating that an instance of a message can be used through the whole pipeline in certain cases, we’d like to do the same with third party types. So conceivably you could have the image pipeline with a single cv::Mat which never gets copied by the middleware. To do this requires some additional intelligence in the intra process manager, but we’ve already got a design and some proof of concepts in the works.\nGiven these features, hopefully there will come a point where you can trust the middleware to handle your data as efficiently as is possible. This will allow you to write performant algorithms without sacrificing modularity or introspection!\n\n\nTooling¶\nOne of the sticking points of Nodelets in ROS 1 was the complexity of defining, building, and using them.\nWe’ve not tackled that problem yet, but we are working on it. We’ve got a port of class loader (https://github.com/ros/class_loader/tree/ros2) and pluginlib (https://github.com/ros/pluginlib/tree/ros2) for ROS 2, but we only have prototypes of the CMake infrastructure which will help users build and run their nodes. Here’s a sketch of the design we expect:\nadd_node(my_node src/my_node.cpp)\ntarget_link_libraries(my_node ${external_dependency_LIBRARIES} ...)\n\n\nWe’ll provide an interface similar to CMake’s add_executable or add_library. This doesn’t preclude the idea of providing a more automatic solution a la ament_cmake_auto.\nThis simple CMake entry will generate a few things:\n\nA marker file used to discover the node by pluginlib.\nA shared library for your node.\nAn executable for your node.\nThe executable can run the node in its own process, or serve as a proxy while the node runs in a different container.\n\n\n\nWe’ll also need to develop the container, which can run nodes inside of itself and is controlled externally by ROS primitives like Services.\nWe’ve got a lot of work to do, but hopefully this tutorial gives you a sense of where we’re going and what we’re trying to do in terms of performance and features.\n\n\n\n\n"}]